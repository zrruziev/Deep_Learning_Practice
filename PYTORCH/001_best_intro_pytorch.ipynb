{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zrruziev/deep_learning_practice/blob/main/PYTORCH/best_intro_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2b7903f7",
      "metadata": {
        "id": "2b7903f7"
      },
      "outputs": [],
      "source": [
        "# # Set the theme\n",
        "# !jt -t onedork -T -N -kl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2dd3de55",
      "metadata": {
        "id": "2dd3de55"
      },
      "outputs": [],
      "source": [
        "# # Reset the org-theme\n",
        "# !jt -r -T -N -kl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "35d43eea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35d43eea",
        "outputId": "adbae1fd-87de-48b5-f6d1-43e1a305c36b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.8/dist-packages (0.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from torchviz) (1.13.1+cu116)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.8/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->torchviz) (4.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchviz"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaf80c6a",
      "metadata": {
        "id": "aaf80c6a"
      },
      "source": [
        "### [the notebook is based on this blogpost...](https://towardsdatascience.com/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e)\n",
        "\n",
        "> To learn better, you can open the blog post on the left side and this notebook on the right side of the screen."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da711fe5",
      "metadata": {
        "id": "da711fe5"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f50353a",
      "metadata": {
        "id": "4f50353a"
      },
      "source": [
        "### Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "de878f50",
      "metadata": {
        "id": "de878f50"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5f6ebdf",
      "metadata": {
        "id": "c5f6ebdf"
      },
      "source": [
        "> ### `y = a + bx + gauss_noise`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "164af5fc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "164af5fc",
        "outputId": "3410fd02-a1a7-4e72-d231-adbded228686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 80 samples with 80 labels\n",
            "valid: 20 samples with 20 labels\n"
          ]
        }
      ],
      "source": [
        "# Data Generation\n",
        "np.random.seed(42)\n",
        "x = np.random.rand(100, 1)\n",
        "y = 1 + 2 * x + .1 * np.random.randn(100, 1)\n",
        "\n",
        "# Shuffles the indices\n",
        "idx = np.arange(100)\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "# Uses first 80 random indices for train\n",
        "train_idx = idx[:80]\n",
        "# Uses the remaining indices for validation\n",
        "val_idx = idx[80:]\n",
        "\n",
        "# Generates train and validation sets\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_val, y_val = x[val_idx], y[val_idx]\n",
        "\n",
        "print(f\"train: {len(x_train)} samples with {len(y_train)} labels\")\n",
        "print(f\"valid: {len(x_val)} samples with {len(y_val)} labels\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "69b89436",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "69b89436",
        "outputId": "e5253611-97e0-4656-d92b-a03aeb7496c0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plotting the data\n",
        "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
        "ax[0].scatter(x_train, y_train, color=\"blue\", label=\"Train\")\n",
        "ax[0].set_title(\"Train Data\")\n",
        "ax[0].set_xlabel(\"x\")\n",
        "ax[0].set_ylabel(\"y\")\n",
        "ax[0].legend()\n",
        "\n",
        "ax[1].scatter(x_val, y_val, color=\"red\", label=\"Validation\")\n",
        "ax[1].set_title(\"Validation Data\")\n",
        "ax[1].set_xlabel(\"x\")\n",
        "ax[1].set_ylabel(\"y\")\n",
        "ax[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02e045da",
      "metadata": {
        "id": "02e045da"
      },
      "source": [
        "## Numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ad7ab9a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad7ab9a3",
        "outputId": "16daaa58-35ca-4c3e-fc80-96ddd8c2110d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized values\n",
            "[0.49671415] [-0.1382643]\n",
            "\n",
            "After 1000 epochs\n",
            "[1.02354094] [1.96896411]\n",
            "\n",
            "sklearn results\n",
            "[1.02354075] [1.96896447]\n"
          ]
        }
      ],
      "source": [
        "# Initializes parameters \"a\" and \"b\" randomly\n",
        "np.random.seed(42)\n",
        "a = np.random.randn(1)\n",
        "b = np.random.randn(1)\n",
        "\n",
        "print(\"Initialized values\")\n",
        "print(a, b)\n",
        "\n",
        "# Sets learning rate\n",
        "lr = 1e-1\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # Computes our model's predicted output\n",
        "    yhat = a + b * x_train\n",
        "    \n",
        "    # How wrong is our model? That's the error! \n",
        "    error = (y_train - yhat)\n",
        "    # It is a regression, so it computes mean squared error (MSE)\n",
        "    loss = (error ** 2).mean()\n",
        "    \n",
        "    # Computes gradients for both \"a\" and \"b\" parameters\n",
        "    a_grad = -2 * error.mean()\n",
        "    b_grad = -2 * (x_train * error).mean()\n",
        "    \n",
        "    # Updates parameters using gradients and the learning rate\n",
        "    a = a - lr * a_grad\n",
        "    b = b - lr * b_grad\n",
        "\n",
        "print(\"\\nAfter 1000 epochs\")    \n",
        "print(a, b)\n",
        "\n",
        "# Sanity Check: do we get the same results as our gradient descent?\n",
        "from sklearn.linear_model import LinearRegression\n",
        "linr = LinearRegression()\n",
        "linr.fit(x_train, y_train)\n",
        "print(\"\\nsklearn results\")\n",
        "print(linr.intercept_, linr.coef_[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52b92d42",
      "metadata": {
        "id": "52b92d42"
      },
      "source": [
        "## Pytorch "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "018e51ae",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "018e51ae",
        "outputId": "17a25a3c-4b2a-4251-b506-804f06b69971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.FloatTensor\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "from torchviz import make_dot\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "\n",
        "# Our data was in Numpy arrays, but we need to transform them into PyTorch's Tensors\n",
        "# and then we send them to the chosen device\n",
        "x_train_tensor = torch.from_numpy(x_train).float().to(device)\n",
        "y_train_tensor = torch.from_numpy(y_train).float().to(device)\n",
        "\n",
        "# Here we can see the difference - notice that .type() is more useful\n",
        "# since it also tells us WHERE the tensor is (device)\n",
        "print(type(x_train), type(x_train_tensor), x_train_tensor.type())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a7a64d78",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7a64d78",
        "outputId": "1a41f405-6bce-43d8-b01e-ddb25cd6ff32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3233], requires_grad=True) tensor([-0.3782], requires_grad=True)\n",
            "tensor([-0.2534], requires_grad=True) tensor([-0.4644], requires_grad=True)\n",
            "tensor([0.0759], requires_grad=True) tensor([0.8038], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# FIRST\n",
        "# Initializes parameters \"a\" and \"b\" randomly, ALMOST as we did in Numpy\n",
        "# since we want to apply gradient descent on these parameters, we need\n",
        "# to set REQUIRES_GRAD = TRUE\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
        "print(a, b)\n",
        "\n",
        "# SECOND\n",
        "# But what if we want to run it on a GPU? We could just send them to device, right?\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float).to(device)\n",
        "print(a, b)\n",
        "# Sorry, but NO! The to(device) \"shadows\" the gradient...\n",
        "\n",
        "# THIRD\n",
        "# We can either create regular tensors and send them to the device (as we did with our data)\n",
        "a = torch.randn(1, dtype=torch.float).to(device)\n",
        "b = torch.randn(1, dtype=torch.float).to(device)\n",
        "# and THEN set them as requiring gradients...\n",
        "a.requires_grad_()\n",
        "b.requires_grad_()\n",
        "print(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "eb384325",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb384325",
        "outputId": "e3e3db02-a9b7-484d-cdbd-8909fc12b99d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# We can specify the device at the moment of creation - RECOMMENDED!\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print(a, b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c3d70871",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3d70871",
        "outputId": "6881fc9b-9be0-43a8-ed33-01e930c2e024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-3.1125])\n",
            "tensor([-1.8156])\n",
            "tensor([-2.3184])\n",
            "tensor([-1.4064])\n",
            "tensor([-1.7219])\n",
            "tensor([-1.0982])\n",
            "tensor([-1.2737])\n",
            "tensor([-0.8659])\n",
            "tensor([-0.9372])\n",
            "tensor([-0.6906])\n",
            "tensor([-0.6845])\n",
            "tensor([-0.5583])\n",
            "tensor([-0.4948])\n",
            "tensor([-0.4582])\n",
            "tensor([-0.3526])\n",
            "tensor([-0.3824])\n",
            "tensor([-0.2459])\n",
            "tensor([-0.3248])\n",
            "tensor([-0.1660])\n",
            "tensor([-0.2810])\n",
            "tensor([-0.1063])\n",
            "tensor([-0.2475])\n",
            "tensor([-0.0616])\n",
            "tensor([-0.2218])\n",
            "tensor([-0.0283])\n",
            "tensor([-0.2019])\n",
            "tensor([-0.0036])\n",
            "tensor([-0.1864])\n",
            "tensor([0.0147])\n",
            "tensor([-0.1743])\n",
            "tensor([0.0283])\n",
            "tensor([-0.1646])\n",
            "tensor([0.0382])\n",
            "tensor([-0.1568])\n",
            "tensor([0.0453])\n",
            "tensor([-0.1505])\n",
            "tensor([0.0505])\n",
            "tensor([-0.1452])\n",
            "tensor([0.0541])\n",
            "tensor([-0.1408])\n",
            "tensor([0.0566])\n",
            "tensor([-0.1370])\n",
            "tensor([0.0582])\n",
            "tensor([-0.1337])\n",
            "tensor([0.0592])\n",
            "tensor([-0.1307])\n",
            "tensor([0.0597])\n",
            "tensor([-0.1280])\n",
            "tensor([0.0599])\n",
            "tensor([-0.1255])\n",
            "tensor([0.0598])\n",
            "tensor([-0.1232])\n",
            "tensor([0.0594])\n",
            "tensor([-0.1211])\n",
            "tensor([0.0590])\n",
            "tensor([-0.1190])\n",
            "tensor([0.0584])\n",
            "tensor([-0.1170])\n",
            "tensor([0.0578])\n",
            "tensor([-0.1151])\n",
            "tensor([0.0571])\n",
            "tensor([-0.1133])\n",
            "tensor([0.0564])\n",
            "tensor([-0.1115])\n",
            "tensor([0.0557])\n",
            "tensor([-0.1098])\n",
            "tensor([0.0549])\n",
            "tensor([-0.1081])\n",
            "tensor([0.0541])\n",
            "tensor([-0.1064])\n",
            "tensor([0.0534])\n",
            "tensor([-0.1048])\n",
            "tensor([0.0526])\n",
            "tensor([-0.1032])\n",
            "tensor([0.0518])\n",
            "tensor([-0.1016])\n",
            "tensor([0.0511])\n",
            "tensor([-0.1001])\n",
            "tensor([0.0503])\n",
            "tensor([-0.0985])\n",
            "tensor([0.0496])\n",
            "tensor([-0.0970])\n",
            "tensor([0.0488])\n",
            "tensor([-0.0956])\n",
            "tensor([0.0481])\n",
            "tensor([-0.0941])\n",
            "tensor([0.0474])\n",
            "tensor([-0.0927])\n",
            "tensor([0.0466])\n",
            "tensor([-0.0913])\n",
            "tensor([0.0459])\n",
            "tensor([-0.0899])\n",
            "tensor([0.0453])\n",
            "tensor([-0.0886])\n",
            "tensor([0.0446])\n",
            "tensor([-0.0872])\n",
            "tensor([0.0439])\n",
            "tensor([-0.0859])\n",
            "tensor([0.0432])\n",
            "tensor([-0.0846])\n",
            "tensor([0.0426])\n",
            "tensor([-0.0833])\n",
            "tensor([0.0419])\n",
            "tensor([-0.0821])\n",
            "tensor([0.0413])\n",
            "tensor([-0.0808])\n",
            "tensor([0.0407])\n",
            "tensor([-0.0796])\n",
            "tensor([0.0401])\n",
            "tensor([-0.0784])\n",
            "tensor([0.0395])\n",
            "tensor([-0.0772])\n",
            "tensor([0.0389])\n",
            "tensor([-0.0761])\n",
            "tensor([0.0383])\n",
            "tensor([-0.0749])\n",
            "tensor([0.0377])\n",
            "tensor([-0.0738])\n",
            "tensor([0.0371])\n",
            "tensor([-0.0727])\n",
            "tensor([0.0366])\n",
            "tensor([-0.0716])\n",
            "tensor([0.0360])\n",
            "tensor([-0.0705])\n",
            "tensor([0.0355])\n",
            "tensor([-0.0694])\n",
            "tensor([0.0349])\n",
            "tensor([-0.0684])\n",
            "tensor([0.0344])\n",
            "tensor([-0.0673])\n",
            "tensor([0.0339])\n",
            "tensor([-0.0663])\n",
            "tensor([0.0334])\n",
            "tensor([-0.0653])\n",
            "tensor([0.0329])\n",
            "tensor([-0.0643])\n",
            "tensor([0.0324])\n",
            "tensor([-0.0634])\n",
            "tensor([0.0319])\n",
            "tensor([-0.0624])\n",
            "tensor([0.0314])\n",
            "tensor([-0.0615])\n",
            "tensor([0.0309])\n",
            "tensor([-0.0605])\n",
            "tensor([0.0305])\n",
            "tensor([-0.0596])\n",
            "tensor([0.0300])\n",
            "tensor([-0.0587])\n",
            "tensor([0.0296])\n",
            "tensor([-0.0578])\n",
            "tensor([0.0291])\n",
            "tensor([-0.0570])\n",
            "tensor([0.0287])\n",
            "tensor([-0.0561])\n",
            "tensor([0.0282])\n",
            "tensor([-0.0552])\n",
            "tensor([0.0278])\n",
            "tensor([-0.0544])\n",
            "tensor([0.0274])\n",
            "tensor([-0.0536])\n",
            "tensor([0.0270])\n",
            "tensor([-0.0528])\n",
            "tensor([0.0266])\n",
            "tensor([-0.0520])\n",
            "tensor([0.0262])\n",
            "tensor([-0.0512])\n",
            "tensor([0.0258])\n",
            "tensor([-0.0504])\n",
            "tensor([0.0254])\n",
            "tensor([-0.0497])\n",
            "tensor([0.0250])\n",
            "tensor([-0.0489])\n",
            "tensor([0.0246])\n",
            "tensor([-0.0482])\n",
            "tensor([0.0242])\n",
            "tensor([-0.0474])\n",
            "tensor([0.0239])\n",
            "tensor([-0.0467])\n",
            "tensor([0.0235])\n",
            "tensor([-0.0460])\n",
            "tensor([0.0232])\n",
            "tensor([-0.0453])\n",
            "tensor([0.0228])\n",
            "tensor([-0.0446])\n",
            "tensor([0.0225])\n",
            "tensor([-0.0440])\n",
            "tensor([0.0221])\n",
            "tensor([-0.0433])\n",
            "tensor([0.0218])\n",
            "tensor([-0.0426])\n",
            "tensor([0.0215])\n",
            "tensor([-0.0420])\n",
            "tensor([0.0211])\n",
            "tensor([-0.0414])\n",
            "tensor([0.0208])\n",
            "tensor([-0.0407])\n",
            "tensor([0.0205])\n",
            "tensor([-0.0401])\n",
            "tensor([0.0202])\n",
            "tensor([-0.0395])\n",
            "tensor([0.0199])\n",
            "tensor([-0.0389])\n",
            "tensor([0.0196])\n",
            "tensor([-0.0383])\n",
            "tensor([0.0193])\n",
            "tensor([-0.0378])\n",
            "tensor([0.0190])\n",
            "tensor([-0.0372])\n",
            "tensor([0.0187])\n",
            "tensor([-0.0366])\n",
            "tensor([0.0184])\n",
            "tensor([-0.0361])\n",
            "tensor([0.0182])\n",
            "tensor([-0.0355])\n",
            "tensor([0.0179])\n",
            "tensor([-0.0350])\n",
            "tensor([0.0176])\n",
            "tensor([-0.0345])\n",
            "tensor([0.0173])\n",
            "tensor([-0.0339])\n",
            "tensor([0.0171])\n",
            "tensor([-0.0334])\n",
            "tensor([0.0168])\n",
            "tensor([-0.0329])\n",
            "tensor([0.0166])\n",
            "tensor([-0.0324])\n",
            "tensor([0.0163])\n",
            "tensor([-0.0319])\n",
            "tensor([0.0161])\n",
            "tensor([-0.0315])\n",
            "tensor([0.0158])\n",
            "tensor([-0.0310])\n",
            "tensor([0.0156])\n",
            "tensor([-0.0305])\n",
            "tensor([0.0154])\n",
            "tensor([-0.0301])\n",
            "tensor([0.0151])\n",
            "tensor([-0.0296])\n",
            "tensor([0.0149])\n",
            "tensor([-0.0291])\n",
            "tensor([0.0147])\n",
            "tensor([-0.0287])\n",
            "tensor([0.0145])\n",
            "tensor([-0.0283])\n",
            "tensor([0.0142])\n",
            "tensor([-0.0278])\n",
            "tensor([0.0140])\n",
            "tensor([-0.0274])\n",
            "tensor([0.0138])\n",
            "tensor([-0.0270])\n",
            "tensor([0.0136])\n",
            "tensor([-0.0266])\n",
            "tensor([0.0134])\n",
            "tensor([-0.0262])\n",
            "tensor([0.0132])\n",
            "tensor([-0.0258])\n",
            "tensor([0.0130])\n",
            "tensor([-0.0254])\n",
            "tensor([0.0128])\n",
            "tensor([-0.0250])\n",
            "tensor([0.0126])\n",
            "tensor([-0.0247])\n",
            "tensor([0.0124])\n",
            "tensor([-0.0243])\n",
            "tensor([0.0122])\n",
            "tensor([-0.0239])\n",
            "tensor([0.0120])\n",
            "tensor([-0.0236])\n",
            "tensor([0.0119])\n",
            "tensor([-0.0232])\n",
            "tensor([0.0117])\n",
            "tensor([-0.0228])\n",
            "tensor([0.0115])\n",
            "tensor([-0.0225])\n",
            "tensor([0.0113])\n",
            "tensor([-0.0222])\n",
            "tensor([0.0112])\n",
            "tensor([-0.0218])\n",
            "tensor([0.0110])\n",
            "tensor([-0.0215])\n",
            "tensor([0.0108])\n",
            "tensor([-0.0212])\n",
            "tensor([0.0107])\n",
            "tensor([-0.0209])\n",
            "tensor([0.0105])\n",
            "tensor([-0.0205])\n",
            "tensor([0.0103])\n",
            "tensor([-0.0202])\n",
            "tensor([0.0102])\n",
            "tensor([-0.0199])\n",
            "tensor([0.0100])\n",
            "tensor([-0.0196])\n",
            "tensor([0.0099])\n",
            "tensor([-0.0193])\n",
            "tensor([0.0097])\n",
            "tensor([-0.0190])\n",
            "tensor([0.0096])\n",
            "tensor([-0.0187])\n",
            "tensor([0.0094])\n",
            "tensor([-0.0185])\n",
            "tensor([0.0093])\n",
            "tensor([-0.0182])\n",
            "tensor([0.0092])\n",
            "tensor([-0.0179])\n",
            "tensor([0.0090])\n",
            "tensor([-0.0176])\n",
            "tensor([0.0089])\n",
            "tensor([-0.0174])\n",
            "tensor([0.0087])\n",
            "tensor([-0.0171])\n",
            "tensor([0.0086])\n",
            "tensor([-0.0169])\n",
            "tensor([0.0085])\n",
            "tensor([-0.0166])\n",
            "tensor([0.0084])\n",
            "tensor([-0.0163])\n",
            "tensor([0.0082])\n",
            "tensor([-0.0161])\n",
            "tensor([0.0081])\n",
            "tensor([-0.0159])\n",
            "tensor([0.0080])\n",
            "tensor([-0.0156])\n",
            "tensor([0.0079])\n",
            "tensor([-0.0154])\n",
            "tensor([0.0077])\n",
            "tensor([-0.0151])\n",
            "tensor([0.0076])\n",
            "tensor([-0.0149])\n",
            "tensor([0.0075])\n",
            "tensor([-0.0147])\n",
            "tensor([0.0074])\n",
            "tensor([-0.0145])\n",
            "tensor([0.0073])\n",
            "tensor([-0.0143])\n",
            "tensor([0.0072])\n",
            "tensor([-0.0140])\n",
            "tensor([0.0071])\n",
            "tensor([-0.0138])\n",
            "tensor([0.0070])\n",
            "tensor([-0.0136])\n",
            "tensor([0.0069])\n",
            "tensor([-0.0134])\n",
            "tensor([0.0068])\n",
            "tensor([-0.0132])\n",
            "tensor([0.0066])\n",
            "tensor([-0.0130])\n",
            "tensor([0.0065])\n",
            "tensor([-0.0128])\n",
            "tensor([0.0064])\n",
            "tensor([-0.0126])\n",
            "tensor([0.0064])\n",
            "tensor([-0.0124])\n",
            "tensor([0.0063])\n",
            "tensor([-0.0122])\n",
            "tensor([0.0062])\n",
            "tensor([-0.0121])\n",
            "tensor([0.0061])\n",
            "tensor([-0.0119])\n",
            "tensor([0.0060])\n",
            "tensor([-0.0117])\n",
            "tensor([0.0059])\n",
            "tensor([-0.0115])\n",
            "tensor([0.0058])\n",
            "tensor([-0.0113])\n",
            "tensor([0.0057])\n",
            "tensor([-0.0112])\n",
            "tensor([0.0056])\n",
            "tensor([-0.0110])\n",
            "tensor([0.0055])\n",
            "tensor([-0.0108])\n",
            "tensor([0.0055])\n",
            "tensor([-0.0107])\n",
            "tensor([0.0054])\n",
            "tensor([-0.0105])\n",
            "tensor([0.0053])\n",
            "tensor([-0.0104])\n",
            "tensor([0.0052])\n",
            "tensor([-0.0102])\n",
            "tensor([0.0051])\n",
            "tensor([-0.0100])\n",
            "tensor([0.0051])\n",
            "tensor([-0.0099])\n",
            "tensor([0.0050])\n",
            "tensor([-0.0097])\n",
            "tensor([0.0049])\n",
            "tensor([-0.0096])\n",
            "tensor([0.0048])\n",
            "tensor([-0.0094])\n",
            "tensor([0.0048])\n",
            "tensor([-0.0093])\n",
            "tensor([0.0047])\n",
            "tensor([-0.0092])\n",
            "tensor([0.0046])\n",
            "tensor([-0.0090])\n",
            "tensor([0.0045])\n",
            "tensor([-0.0089])\n",
            "tensor([0.0045])\n",
            "tensor([-0.0088])\n",
            "tensor([0.0044])\n",
            "tensor([-0.0086])\n",
            "tensor([0.0043])\n",
            "tensor([-0.0085])\n",
            "tensor([0.0043])\n",
            "tensor([-0.0084])\n",
            "tensor([0.0042])\n",
            "tensor([-0.0082])\n",
            "tensor([0.0041])\n",
            "tensor([-0.0081])\n",
            "tensor([0.0041])\n",
            "tensor([-0.0080])\n",
            "tensor([0.0040])\n",
            "tensor([-0.0079])\n",
            "tensor([0.0040])\n",
            "tensor([-0.0078])\n",
            "tensor([0.0039])\n",
            "tensor([-0.0076])\n",
            "tensor([0.0038])\n",
            "tensor([-0.0075])\n",
            "tensor([0.0038])\n",
            "tensor([-0.0074])\n",
            "tensor([0.0037])\n",
            "tensor([-0.0073])\n",
            "tensor([0.0037])\n",
            "tensor([-0.0072])\n",
            "tensor([0.0036])\n",
            "tensor([-0.0071])\n",
            "tensor([0.0036])\n",
            "tensor([-0.0070])\n",
            "tensor([0.0035])\n",
            "tensor([-0.0069])\n",
            "tensor([0.0035])\n",
            "tensor([-0.0068])\n",
            "tensor([0.0034])\n",
            "tensor([-0.0067])\n",
            "tensor([0.0034])\n",
            "tensor([-0.0066])\n",
            "tensor([0.0033])\n",
            "tensor([-0.0065])\n",
            "tensor([0.0033])\n",
            "tensor([-0.0064])\n",
            "tensor([0.0032])\n",
            "tensor([-0.0063])\n",
            "tensor([0.0032])\n",
            "tensor([-0.0062])\n",
            "tensor([0.0031])\n",
            "tensor([-0.0061])\n",
            "tensor([0.0031])\n",
            "tensor([-0.0060])\n",
            "tensor([0.0030])\n",
            "tensor([-0.0059])\n",
            "tensor([0.0030])\n",
            "tensor([-0.0058])\n",
            "tensor([0.0029])\n",
            "tensor([-0.0057])\n",
            "tensor([0.0029])\n",
            "tensor([-0.0056])\n",
            "tensor([0.0028])\n",
            "tensor([-0.0055])\n",
            "tensor([0.0028])\n",
            "tensor([-0.0055])\n",
            "tensor([0.0027])\n",
            "tensor([-0.0054])\n",
            "tensor([0.0027])\n",
            "tensor([-0.0053])\n",
            "tensor([0.0027])\n",
            "tensor([-0.0052])\n",
            "tensor([0.0026])\n",
            "tensor([-0.0051])\n",
            "tensor([0.0026])\n",
            "tensor([-0.0051])\n",
            "tensor([0.0025])\n",
            "tensor([-0.0050])\n",
            "tensor([0.0025])\n",
            "tensor([-0.0049])\n",
            "tensor([0.0025])\n",
            "tensor([-0.0048])\n",
            "tensor([0.0024])\n",
            "tensor([-0.0048])\n",
            "tensor([0.0024])\n",
            "tensor([-0.0047])\n",
            "tensor([0.0024])\n",
            "tensor([-0.0046])\n",
            "tensor([0.0023])\n",
            "tensor([-0.0046])\n",
            "tensor([0.0023])\n",
            "tensor([-0.0045])\n",
            "tensor([0.0023])\n",
            "tensor([-0.0044])\n",
            "tensor([0.0022])\n",
            "tensor([-0.0043])\n",
            "tensor([0.0022])\n",
            "tensor([-0.0043])\n",
            "tensor([0.0022])\n",
            "tensor([-0.0042])\n",
            "tensor([0.0021])\n",
            "tensor([-0.0042])\n",
            "tensor([0.0021])\n",
            "tensor([-0.0041])\n",
            "tensor([0.0021])\n",
            "tensor([-0.0040])\n",
            "tensor([0.0020])\n",
            "tensor([-0.0040])\n",
            "tensor([0.0020])\n",
            "tensor([-0.0039])\n",
            "tensor([0.0020])\n",
            "tensor([-0.0038])\n",
            "tensor([0.0019])\n",
            "tensor([-0.0038])\n",
            "tensor([0.0019])\n",
            "tensor([-0.0037])\n",
            "tensor([0.0019])\n",
            "tensor([-0.0037])\n",
            "tensor([0.0019])\n",
            "tensor([-0.0036])\n",
            "tensor([0.0018])\n",
            "tensor([-0.0036])\n",
            "tensor([0.0018])\n",
            "tensor([-0.0035])\n",
            "tensor([0.0018])\n",
            "tensor([-0.0035])\n",
            "tensor([0.0017])\n",
            "tensor([-0.0034])\n",
            "tensor([0.0017])\n",
            "tensor([-0.0034])\n",
            "tensor([0.0017])\n",
            "tensor([-0.0033])\n",
            "tensor([0.0017])\n",
            "tensor([-0.0033])\n",
            "tensor([0.0016])\n",
            "tensor([-0.0032])\n",
            "tensor([0.0016])\n",
            "tensor([-0.0032])\n",
            "tensor([0.0016])\n",
            "tensor([-0.0031])\n",
            "tensor([0.0016])\n",
            "tensor([-0.0031])\n",
            "tensor([0.0015])\n",
            "tensor([-0.0030])\n",
            "tensor([0.0015])\n",
            "tensor([-0.0030])\n",
            "tensor([0.0015])\n",
            "tensor([-0.0029])\n",
            "tensor([0.0015])\n",
            "tensor([-0.0029])\n",
            "tensor([0.0015])\n",
            "tensor([-0.0028])\n",
            "tensor([0.0014])\n",
            "tensor([-0.0028])\n",
            "tensor([0.0014])\n",
            "tensor([-0.0028])\n",
            "tensor([0.0014])\n",
            "tensor([-0.0027])\n",
            "tensor([0.0014])\n",
            "tensor([-0.0027])\n",
            "tensor([0.0013])\n",
            "tensor([-0.0026])\n",
            "tensor([0.0013])\n",
            "tensor([-0.0026])\n",
            "tensor([0.0013])\n",
            "tensor([-0.0026])\n",
            "tensor([0.0013])\n",
            "tensor([-0.0025])\n",
            "tensor([0.0013])\n",
            "tensor([-0.0025])\n",
            "tensor([0.0012])\n",
            "tensor([-0.0024])\n",
            "tensor([0.0012])\n",
            "tensor([-0.0024])\n",
            "tensor([0.0012])\n",
            "tensor([-0.0024])\n",
            "tensor([0.0012])\n",
            "tensor([-0.0023])\n",
            "tensor([0.0012])\n",
            "tensor([-0.0023])\n",
            "tensor([0.0012])\n",
            "tensor([-0.0023])\n",
            "tensor([0.0011])\n",
            "tensor([-0.0022])\n",
            "tensor([0.0011])\n",
            "tensor([-0.0022])\n",
            "tensor([0.0011])\n",
            "tensor([-0.0022])\n",
            "tensor([0.0011])\n",
            "tensor([-0.0021])\n",
            "tensor([0.0011])\n",
            "tensor([-0.0021])\n",
            "tensor([0.0011])\n",
            "tensor([-0.0021])\n",
            "tensor([0.0010])\n",
            "tensor([-0.0020])\n",
            "tensor([0.0010])\n",
            "tensor([-0.0020])\n",
            "tensor([0.0010])\n",
            "tensor([-0.0020])\n",
            "tensor([0.0010])\n",
            "tensor([-0.0019])\n",
            "tensor([0.0010])\n",
            "tensor([-0.0019])\n",
            "tensor([0.0010])\n",
            "tensor([-0.0019])\n",
            "tensor([0.0009])\n",
            "tensor([-0.0019])\n",
            "tensor([0.0009])\n",
            "tensor([-0.0018])\n",
            "tensor([0.0009])\n",
            "tensor([-0.0018])\n",
            "tensor([0.0009])\n",
            "tensor([-0.0018])\n",
            "tensor([0.0009])\n",
            "tensor([-0.0017])\n",
            "tensor([0.0009])\n",
            "tensor([-0.0017])\n",
            "tensor([0.0009])\n",
            "tensor([-0.0017])\n",
            "tensor([0.0009])\n",
            "tensor([-0.0017])\n",
            "tensor([0.0008])\n",
            "tensor([-0.0016])\n",
            "tensor([0.0008])\n",
            "tensor([-0.0016])\n",
            "tensor([0.0008])\n",
            "tensor([-0.0016])\n",
            "tensor([0.0008])\n",
            "tensor([-0.0016])\n",
            "tensor([0.0008])\n",
            "tensor([-0.0015])\n",
            "tensor([0.0008])\n",
            "tensor([-0.0015])\n",
            "tensor([0.0008])\n",
            "tensor([-0.0015])\n",
            "tensor([0.0008])\n",
            "tensor([-0.0015])\n",
            "tensor([0.0007])\n",
            "tensor([-0.0015])\n",
            "tensor([0.0007])\n",
            "tensor([-0.0014])\n",
            "tensor([0.0007])\n",
            "tensor([-0.0014])\n",
            "tensor([0.0007])\n",
            "tensor([-0.0014])\n",
            "tensor([0.0007])\n",
            "tensor([-0.0014])\n",
            "tensor([0.0007])\n",
            "tensor([-0.0013])\n",
            "tensor([0.0007])\n",
            "tensor([-0.0013])\n",
            "tensor([0.0007])\n",
            "tensor([-0.0013])\n",
            "tensor([0.0007])\n",
            "tensor([-0.0013])\n",
            "tensor([0.0006])\n",
            "tensor([-0.0013])\n",
            "tensor([0.0006])\n",
            "tensor([-0.0012])\n",
            "tensor([0.0006])\n",
            "tensor([-0.0012])\n",
            "tensor([0.0006])\n",
            "tensor([-0.0012])\n",
            "tensor([0.0006])\n",
            "tensor([-0.0012])\n",
            "tensor([0.0006])\n",
            "tensor([-0.0012])\n",
            "tensor([0.0006])\n",
            "tensor([-0.0012])\n",
            "tensor([0.0006])\n",
            "tensor([-0.0011])\n",
            "tensor([0.0006])\n",
            "tensor([-0.0011])\n",
            "tensor([0.0006])\n",
            "tensor([-0.0011])\n",
            "tensor([0.0006])\n",
            "tensor([-0.0011])\n",
            "tensor([0.0005])\n",
            "tensor([-0.0011])\n",
            "tensor([0.0005])\n",
            "tensor([-0.0011])\n",
            "tensor([0.0005])\n",
            "tensor([-0.0010])\n",
            "tensor([0.0005])\n",
            "tensor([-0.0010])\n",
            "tensor([0.0005])\n",
            "tensor([-0.0010])\n",
            "tensor([0.0005])\n",
            "tensor([-0.0010])\n",
            "tensor([0.0005])\n",
            "tensor([-0.0010])\n",
            "tensor([0.0005])\n",
            "tensor([-0.0010])\n",
            "tensor([0.0005])\n",
            "tensor([-0.0009])\n",
            "tensor([0.0005])\n",
            "tensor([-0.0009])\n",
            "tensor([0.0005])\n",
            "tensor([-0.0009])\n",
            "tensor([0.0005])\n",
            "tensor([-0.0009])\n",
            "tensor([0.0005])\n",
            "tensor([-0.0009])\n",
            "tensor([0.0004])\n",
            "tensor([-0.0009])\n",
            "tensor([0.0004])\n",
            "tensor([-0.0009])\n",
            "tensor([0.0004])\n",
            "tensor([-0.0009])\n",
            "tensor([0.0004])\n",
            "tensor([-0.0008])\n",
            "tensor([0.0004])\n",
            "tensor([-0.0008])\n",
            "tensor([0.0004])\n",
            "tensor([-0.0008])\n",
            "tensor([0.0004])\n",
            "tensor([-0.0008])\n",
            "tensor([0.0004])\n",
            "tensor([-0.0008])\n",
            "tensor([0.0004])\n",
            "tensor([-0.0008])\n",
            "tensor([0.0004])\n",
            "tensor([-0.0008])\n",
            "tensor([0.0004])\n",
            "tensor([-0.0008])\n",
            "tensor([0.0004])\n",
            "tensor([-0.0007])\n",
            "tensor([0.0004])\n",
            "tensor([-0.0007])\n",
            "tensor([0.0004])\n",
            "tensor([-0.0007])\n",
            "tensor([0.0004])\n",
            "tensor([-0.0007])\n",
            "tensor([0.0004])\n",
            "tensor([-0.0007])\n",
            "tensor([0.0004])\n",
            "tensor([-0.0007])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0007])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0007])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0007])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0006])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0006])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0006])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0006])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0006])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0006])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0006])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0006])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0006])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0006])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0006])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0005])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0005])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0005])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0005])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0005])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0005])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0005])\n",
            "tensor([0.0003])\n",
            "tensor([-0.0005])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0005])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0005])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0005])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0005])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0005])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0005])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0004])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0004])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0004])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0004])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0004])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0004])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0004])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0004])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0004])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0004])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0004])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0004])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0004])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0004])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0004])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0004])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0002])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0003])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0002])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0002])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0002])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0002])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0002])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0002])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0002])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0002])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0002])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0002])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0002])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0002])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0002])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0002])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0002])\n",
            "tensor([0.0001])\n",
            "tensor([-0.0002])\n",
            "tensor([9.9593e-05])\n",
            "tensor([-0.0002])\n",
            "tensor([9.7900e-05])\n",
            "tensor([-0.0002])\n",
            "tensor([9.6528e-05])\n",
            "tensor([-0.0002])\n",
            "tensor([9.5082e-05])\n",
            "tensor([-0.0002])\n",
            "tensor([9.3635e-05])\n",
            "tensor([-0.0002])\n",
            "tensor([9.2131e-05])\n",
            "tensor([-0.0002])\n",
            "tensor([9.0877e-05])\n",
            "tensor([-0.0002])\n",
            "tensor([8.9555e-05])\n",
            "tensor([-0.0002])\n",
            "tensor([8.8250e-05])\n",
            "tensor([-0.0002])\n",
            "tensor([8.6921e-05])\n",
            "tensor([-0.0002])\n",
            "tensor([8.5517e-05])\n",
            "tensor([-0.0002])\n",
            "tensor([8.4098e-05])\n",
            "tensor([-0.0002])\n",
            "tensor([8.2713e-05])\n",
            "tensor([-0.0002])\n",
            "tensor([8.1572e-05])\n",
            "tensor([-0.0002])\n",
            "tensor([8.0483e-05])\n",
            "tensor([-0.0002])\n",
            "tensor([7.9146e-05])\n",
            "tensor([-0.0002])\n",
            "tensor([7.8050e-05])\n",
            "tensor([-0.0002])\n",
            "tensor([7.6955e-05])\n",
            "tensor([-0.0002])\n",
            "tensor([7.5683e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([7.4612e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([7.3319e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([7.2197e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([7.1033e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([6.9905e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([6.8819e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([6.7824e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([6.6845e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([6.5868e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([6.4931e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([6.4093e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([6.3057e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([6.2128e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([6.1230e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([6.0353e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([5.9323e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([5.8341e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([5.7453e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([5.6731e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([5.5748e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([5.4914e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([5.4108e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([5.3403e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([5.2583e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([5.1776e-05])\n",
            "tensor([-0.0001])\n",
            "tensor([5.1086e-05])\n",
            "tensor([-9.9640e-05])\n",
            "tensor([5.0306e-05])\n",
            "tensor([-9.8126e-05])\n",
            "tensor([4.9496e-05])\n",
            "tensor([-9.6684e-05])\n",
            "tensor([4.8649e-05])\n",
            "tensor([-9.5258e-05])\n",
            "tensor([4.7850e-05])\n",
            "tensor([-9.3862e-05])\n",
            "tensor([4.7218e-05])\n",
            "tensor([-9.2392e-05])\n",
            "tensor([4.6494e-05])\n",
            "tensor([-9.0986e-05])\n",
            "tensor([4.5732e-05])\n",
            "tensor([-8.9653e-05])\n",
            "tensor([4.5110e-05])\n",
            "tensor([-8.8274e-05])\n",
            "tensor([4.4386e-05])\n",
            "tensor([-8.6958e-05])\n",
            "tensor([4.3813e-05])\n",
            "tensor([-8.5593e-05])\n",
            "tensor([4.3080e-05])\n",
            "tensor([-8.4333e-05])\n",
            "tensor([4.2503e-05])\n",
            "tensor([-8.3017e-05])\n",
            "tensor([4.1799e-05])\n",
            "tensor([-8.1784e-05])\n",
            "tensor([4.1258e-05])\n",
            "tensor([-8.0489e-05])\n",
            "tensor([4.0557e-05])\n",
            "tensor([-7.9301e-05])\n",
            "tensor([3.9983e-05])\n",
            "tensor([-7.8079e-05])\n",
            "tensor([3.9206e-05])\n",
            "tensor([-7.6996e-05])\n",
            "tensor([3.8651e-05])\n",
            "tensor([-7.5801e-05])\n",
            "tensor([3.8225e-05])\n",
            "tensor([-7.4577e-05])\n",
            "tensor([3.7706e-05])\n",
            "tensor([-7.3411e-05])\n",
            "tensor([3.7102e-05])\n",
            "tensor([-7.2300e-05])\n",
            "tensor([3.6565e-05])\n",
            "tensor([-7.1189e-05])\n",
            "tensor([3.5922e-05])\n",
            "tensor([-7.0154e-05])\n",
            "tensor([3.5395e-05])\n",
            "tensor([-6.9097e-05])\n",
            "tensor([3.4794e-05])\n",
            "tensor([-6.8070e-05])\n",
            "tensor([3.4280e-05])\n",
            "tensor([-6.7045e-05])\n",
            "tensor([3.3686e-05])\n",
            "tensor([-6.6071e-05])\n",
            "tensor([3.3202e-05])\n",
            "tensor([-6.5076e-05])\n",
            "tensor([3.2708e-05])\n",
            "tensor([-6.4071e-05])\n",
            "tensor([3.2351e-05])\n",
            "tensor([-6.3037e-05])\n",
            "tensor([3.1894e-05])\n",
            "tensor([-6.2072e-05])\n",
            "tensor([3.1340e-05])\n",
            "tensor([-6.1164e-05])\n",
            "tensor([3.0885e-05])\n",
            "tensor([-6.0245e-05])\n",
            "tensor([3.0420e-05])\n",
            "tensor([-5.9325e-05])\n",
            "tensor([2.9830e-05])\n",
            "tensor([-5.8491e-05])\n",
            "tensor([2.9391e-05])\n",
            "tensor([-5.7597e-05])\n",
            "tensor([2.8838e-05])\n",
            "tensor([-5.6787e-05])\n",
            "tensor([2.8547e-05])\n",
            "tensor([-5.5845e-05])\n",
            "tensor([2.8067e-05])\n",
            "tensor([-5.5037e-05])\n",
            "tensor([2.7576e-05])\n",
            "tensor([-5.4227e-05])\n",
            "tensor([2.7156e-05])\n",
            "tensor([-5.3419e-05])\n",
            "tensor([2.6734e-05])\n",
            "tensor([-5.2610e-05])\n",
            "tensor([2.6423e-05])\n",
            "tensor([-5.1769e-05])\n",
            "tensor([2.6060e-05])\n",
            "tensor([-5.0979e-05])\n",
            "tensor([2.5657e-05])\n",
            "tensor([-5.0212e-05])\n",
            "tensor([2.5140e-05])\n",
            "tensor([-4.9514e-05])\n",
            "tensor([2.4864e-05])\n",
            "tensor([-4.8710e-05])\n",
            "tensor([2.4471e-05])\n",
            "tensor([-4.7985e-05])\n",
            "tensor([2.3978e-05])\n",
            "tensor([-4.7320e-05])\n",
            "tensor([2.3684e-05])\n",
            "tensor([-4.6571e-05])\n",
            "tensor([2.3326e-05])\n",
            "tensor([-4.5856e-05])\n",
            "tensor([2.2852e-05])\n",
            "tensor([-4.5239e-05])\n",
            "tensor([2.2600e-05])\n",
            "tensor([-4.4504e-05])\n",
            "tensor([2.2241e-05])\n",
            "tensor([-4.3848e-05])\n",
            "tensor([2.1889e-05])\n",
            "tensor([-4.3181e-05])\n",
            "tensor([2.1611e-05])\n",
            "tensor([-4.2512e-05])\n",
            "tensor([2.1398e-05])\n",
            "tensor([-4.1804e-05])\n",
            "tensor([2.1037e-05])\n",
            "tensor([-4.1199e-05])\n",
            "tensor([2.0692e-05])\n",
            "tensor([-4.0582e-05])\n",
            "tensor([2.0462e-05])\n",
            "tensor([-3.9930e-05])\n",
            "tensor([2.0137e-05])\n",
            "tensor([-3.9340e-05])\n",
            "tensor([1.9828e-05])\n",
            "tensor([-3.8749e-05])\n",
            "tensor([1.9468e-05])\n",
            "tensor([-3.8180e-05])\n",
            "tensor([1.9222e-05])\n",
            "tensor([-3.7587e-05])\n",
            "tensor([1.9011e-05])\n",
            "tensor([-3.6970e-05])\n",
            "tensor([1.8727e-05])\n",
            "tensor([-3.6407e-05])\n",
            "tensor([1.8391e-05])\n",
            "tensor([-3.5875e-05])\n",
            "tensor([1.8169e-05])\n",
            "tensor([-3.5314e-05])\n",
            "tensor([1.7992e-05])\n",
            "tensor([-3.4718e-05])\n",
            "tensor([1.7693e-05])\n",
            "tensor([-3.4219e-05])\n",
            "tensor([1.7415e-05])\n",
            "tensor([-3.3694e-05])\n",
            "tensor([1.6961e-05])\n",
            "tensor([-3.3285e-05])\n",
            "tensor([1.6763e-05])\n",
            "tensor([-3.2756e-05])\n",
            "tensor([1.6480e-05])\n",
            "tensor([-3.2284e-05])\n",
            "tensor([1.6171e-05])\n",
            "tensor([-3.1832e-05])\n",
            "tensor([1.5910e-05])\n",
            "tensor([-3.1346e-05])\n",
            "tensor([1.5727e-05])\n",
            "tensor([-3.0851e-05])\n",
            "tensor([1.5564e-05])\n",
            "tensor([-3.0346e-05])\n",
            "tensor([1.5290e-05])\n",
            "tensor([-2.9914e-05])\n",
            "tensor([1.4984e-05])\n",
            "tensor([-2.9495e-05])\n",
            "tensor([1.4712e-05])\n",
            "tensor([-2.9066e-05])\n",
            "tensor([1.4538e-05])\n",
            "tensor([-2.8613e-05])\n",
            "tensor([1.4408e-05])\n",
            "tensor([-2.8139e-05])\n",
            "tensor([1.4248e-05])\n",
            "tensor([-2.7681e-05])\n",
            "tensor([1.3953e-05])\n",
            "tensor([-2.7312e-05])\n",
            "tensor([1.3675e-05])\n",
            "tensor([-2.6926e-05])\n",
            "tensor([1.3649e-05])\n",
            "tensor([-2.6420e-05])\n",
            "tensor([1.3521e-05])\n",
            "tensor([-2.5995e-05])\n",
            "tensor([1.3351e-05])\n",
            "tensor([-2.5576e-05])\n",
            "tensor([1.3142e-05])\n",
            "tensor([-2.5200e-05])\n",
            "tensor([1.2852e-05])\n",
            "tensor([-2.4874e-05])\n",
            "tensor([1.2607e-05])\n",
            "tensor([-2.4519e-05])\n",
            "tensor([1.2361e-05])\n",
            "tensor([-2.4165e-05])\n",
            "tensor([1.2212e-05])\n",
            "tensor([-2.3796e-05])\n",
            "tensor([1.2074e-05])\n",
            "tensor([-2.3412e-05])\n",
            "tensor([1.1940e-05])\n",
            "tensor([-2.3022e-05])\n",
            "tensor([1.1697e-05])\n",
            "tensor([-2.2717e-05])\n",
            "tensor([1.1452e-05])\n",
            "tensor([-2.2410e-05])\n",
            "tensor([1.1185e-05])\n",
            "tensor([-2.2110e-05])\n",
            "tensor([1.1190e-05])\n",
            "tensor([-2.1685e-05])\n",
            "tensor([1.1090e-05])\n",
            "tensor([-2.1328e-05])\n",
            "tensor([1.0995e-05])\n",
            "tensor([-2.0965e-05])\n",
            "tensor([1.0843e-05])\n",
            "tensor([-2.0638e-05])\n",
            "tensor([1.0596e-05])\n",
            "tensor([-2.0378e-05])\n",
            "tensor([1.0381e-05])\n",
            "tensor([-2.0099e-05])\n",
            "tensor([1.0169e-05])\n",
            "tensor([-1.9810e-05])\n",
            "tensor([9.9139e-06])\n",
            "tensor([-1.9562e-05])\n",
            "tensor([9.8259e-06])\n",
            "tensor([-1.9239e-05])\n",
            "tensor([9.7388e-06])\n",
            "tensor([-1.8920e-05])\n",
            "tensor([9.5954e-06])\n",
            "tensor([-1.8628e-05])\n",
            "tensor([9.5186e-06])\n",
            "tensor([-1.8313e-05])\n",
            "tensor([9.2844e-06])\n",
            "tensor([-1.8095e-05])\n",
            "tensor([9.0720e-06])\n",
            "tensor([-1.7857e-05])\n",
            "tensor([8.8690e-06])\n",
            "tensor([-1.7605e-05])\n",
            "tensor([8.8969e-06])\n",
            "tensor([-1.7261e-05])\n",
            "tensor([8.7656e-06])\n",
            "tensor([-1.7018e-05])\n",
            "tensor([8.7041e-06])\n",
            "tensor([-1.6719e-05])\n",
            "tensor([8.5849e-06])\n",
            "tensor([-1.6477e-05])\n",
            "tensor([8.4946e-06])\n",
            "tensor([-1.6209e-05])\n",
            "tensor([8.4154e-06])\n",
            "tensor([-1.5922e-05])\n",
            "tensor([8.2180e-06])\n",
            "tensor([-1.5732e-05])\n",
            "tensor([8.0187e-06])\n",
            "tensor([-1.5523e-05])\n",
            "tensor([7.8045e-06])\n",
            "tensor([-1.5342e-05])\n",
            "tensor([7.5679e-06])\n",
            "tensor([-1.5164e-05])\n",
            "tensor([7.6322e-06])\n",
            "tensor([-1.4845e-05])\n",
            "tensor([7.5605e-06])\n",
            "tensor([-1.4611e-05])\n",
            "tensor([7.4748e-06])\n",
            "tensor([-1.4379e-05])\n",
            "tensor([7.3779e-06])\n",
            "tensor([-1.4175e-05])\n",
            "tensor([7.3090e-06])\n",
            "tensor([-1.3923e-05])\n",
            "tensor([7.2317e-06])\n",
            "tensor([-1.3692e-05])\n",
            "tensor([7.0189e-06])\n",
            "tensor([-1.3553e-05])\n",
            "tensor([6.8340e-06])\n",
            "tensor([-1.3394e-05])\n",
            "tensor([6.6645e-06])\n",
            "tensor([-1.3220e-05])\n",
            "tensor([6.4904e-06])\n",
            "tensor([-1.3053e-05])\n",
            "tensor([6.4960e-06])\n",
            "tensor([-1.2812e-05])\n",
            "tensor([6.5668e-06])\n",
            "tensor([-1.2529e-05])\n",
            "tensor([6.3819e-06])\n",
            "tensor([-1.2364e-05])\n",
            "tensor([6.2883e-06])\n",
            "tensor([-1.2195e-05])\n",
            "tensor([6.2520e-06])\n",
            "tensor([-1.1981e-05])\n",
            "tensor([6.1919e-06])\n",
            "tensor([-1.1794e-05])\n",
            "tensor([6.1188e-06])\n",
            "tensor([-1.1604e-05])\n",
            "tensor([6.0387e-06])\n",
            "tensor([-1.1412e-05])\n",
            "tensor([5.9716e-06])\n",
            "tensor([-1.1222e-05])\n",
            "tensor([5.8031e-06])\n",
            "tensor([-1.1110e-05])\n",
            "tensor([5.6336e-06])\n",
            "tensor([-1.0979e-05])\n",
            "tensor([5.4603e-06])\n",
            "tensor([-1.0857e-05])\n",
            "tensor([5.2704e-06])\n",
            "tensor([-1.0748e-05])\n",
            "tensor([5.3230e-06])\n",
            "tensor([-1.0535e-05])\n",
            "tensor([5.3840e-06])\n",
            "tensor([-1.0292e-05])\n",
            "tensor([5.1949e-06])\n",
            "tensor([-1.0185e-05])\n",
            "tensor([5.2750e-06])\n",
            "tensor([-9.9503e-06])\n",
            "tensor([5.2582e-06])\n",
            "tensor([-9.7628e-06])\n",
            "tensor([5.1539e-06])\n",
            "tensor([-9.6364e-06])\n",
            "tensor([5.1362e-06])\n",
            "tensor([-9.4608e-06])\n",
            "tensor([5.0925e-06])\n",
            "tensor([-9.3081e-06])\n",
            "tensor([4.9807e-06])\n",
            "tensor([-9.1949e-06])\n",
            "tensor([4.9304e-06])\n",
            "tensor([-9.0390e-06])\n",
            "tensor([4.8950e-06])\n",
            "tensor([-8.8778e-06])\n",
            "tensor([4.7348e-06])\n",
            "tensor([-8.7903e-06])\n",
            "tensor([4.5747e-06])\n",
            "tensor([-8.7037e-06])\n",
            "tensor([4.4145e-06])\n",
            "tensor([-8.6257e-06])\n",
            "tensor([4.2357e-06])\n",
            "tensor([-8.5547e-06])\n",
            "tensor([4.0680e-06])\n",
            "tensor([-8.4816e-06])\n",
            "tensor([4.1481e-06])\n",
            "tensor([-8.2841e-06])\n",
            "tensor([4.2226e-06])\n",
            "tensor([-8.0937e-06])\n",
            "tensor([4.0773e-06])\n",
            "tensor([-8.0033e-06])\n",
            "tensor([4.1304e-06])\n",
            "tensor([-7.8185e-06])\n",
            "tensor([4.2040e-06])\n",
            "tensor([-7.6303e-06])\n",
            "tensor([3.9209e-06])\n",
            "tensor([-7.6341e-06])\n",
            "tensor([3.8939e-06])\n",
            "tensor([-7.5102e-06])\n",
            "tensor([3.8566e-06])\n",
            "tensor([-7.3886e-06])\n",
            "tensor([3.7849e-06])\n",
            "tensor([-7.3011e-06])\n",
            "tensor([3.7821e-06])\n",
            "tensor([-7.1619e-06])\n",
            "tensor([3.7216e-06])\n",
            "tensor([-7.0529e-06])\n",
            "tensor([3.6652e-06])\n",
            "tensor([-6.9528e-06])\n",
            "tensor([3.6694e-06])\n",
            "tensor([-6.8131e-06])\n",
            "tensor([3.6312e-06])\n",
            "tensor([-6.6911e-06])\n",
            "tensor([3.5805e-06])\n",
            "tensor([-6.5877e-06])\n",
            "tensor([3.5302e-06])\n",
            "tensor([-6.4708e-06])\n",
            "tensor([3.3751e-06])\n",
            "tensor([-6.4364e-06])\n",
            "tensor([3.2438e-06])\n",
            "tensor([-6.3798e-06])\n",
            "tensor([3.0673e-06])\n",
            "tensor([-6.3649e-06])\n",
            "tensor([2.9169e-06])\n",
            "tensor([-6.3283e-06])\n",
            "tensor([3.0063e-06])\n",
            "tensor([-6.1644e-06])\n",
            "tensor([2.8526e-06])\n",
            "tensor([-6.1288e-06])\n",
            "tensor([2.9271e-06])\n",
            "tensor([-5.9761e-06])\n",
            "tensor([3.0342e-06])\n",
            "tensor([-5.8163e-06])\n",
            "tensor([2.9062e-06])\n",
            "tensor([-5.7574e-06])\n",
            "tensor([2.9374e-06])\n",
            "tensor([-5.6359e-06])\n",
            "tensor([3.0212e-06])\n",
            "tensor([-5.4925e-06])\n",
            "tensor([2.9062e-06])\n",
            "tensor([-5.4231e-06])\n",
            "tensor([2.9700e-06])\n",
            "tensor([-5.2867e-06])\n",
            "tensor([2.9458e-06])\n",
            "tensor([-5.2082e-06])\n",
            "tensor([2.9090e-06])\n",
            "tensor([-5.1397e-06])\n",
            "tensor([2.9271e-06])\n",
            "tensor([-5.0352e-06])\n",
            "tensor([2.8824e-06])\n",
            "tensor([-4.9761e-06])\n",
            "tensor([2.8471e-06])\n",
            "tensor([-4.8955e-06])\n",
            "tensor([2.8368e-06])\n",
            "tensor([-4.8168e-06])\n",
            "tensor([2.7912e-06])\n",
            "tensor([-4.7437e-06])\n",
            "tensor([2.7595e-06])\n",
            "tensor([-4.6727e-06])\n",
            "tensor([2.7707e-06])\n",
            "tensor([-4.5723e-06])\n",
            "tensor([2.7129e-06])\n",
            "tensor([-4.5155e-06])\n",
            "tensor([2.6934e-06])\n",
            "tensor([-4.4457e-06])\n",
            "tensor([2.6664e-06])\n",
            "tensor([-4.3549e-06])\n",
            "tensor([2.6403e-06])\n",
            "tensor([-4.2808e-06])\n",
            "tensor([2.6189e-06])\n",
            "tensor([-4.1961e-06])\n",
            "tensor([2.5863e-06])\n",
            "tensor([-4.1244e-06])\n",
            "tensor([2.4531e-06])\n",
            "tensor([-4.1206e-06])\n",
            "tensor([2.3218e-06])\n",
            "tensor([-4.1244e-06])\n",
            "tensor([2.1812e-06])\n",
            "tensor([-4.1162e-06])\n",
            "tensor([2.0419e-06])\n",
            "tensor([-4.1134e-06])\n",
            "tensor([1.9101e-06])\n",
            "tensor([-4.1104e-06])\n",
            "tensor([1.7472e-06])\n",
            "tensor([-4.1234e-06])\n",
            "tensor([1.8640e-06])\n",
            "tensor([-3.9954e-06])\n",
            "tensor([1.7462e-06])\n",
            "tensor([-3.9786e-06])\n",
            "tensor([1.7886e-06])\n",
            "tensor([-3.9116e-06])\n",
            "tensor([1.6550e-06])\n",
            "tensor([-3.9032e-06])\n",
            "tensor([1.7961e-06])\n",
            "tensor([-3.7518e-06])\n",
            "tensor([1.6307e-06])\n",
            "tensor([-3.7816e-06])\n",
            "tensor([1.7220e-06])\n",
            "tensor([-3.6587e-06])\n",
            "tensor([1.8515e-06])\n",
            "tensor([-3.5283e-06])\n",
            "tensor([1.7015e-06])\n",
            "tensor([-3.5372e-06])\n",
            "tensor([1.8058e-06])\n",
            "tensor([-3.4194e-06])\n",
            "tensor([1.6391e-06])\n",
            "tensor([-3.4361e-06])\n",
            "tensor([1.7486e-06])\n",
            "tensor([-3.3178e-06])\n",
            "tensor([1.8612e-06])\n",
            "tensor([-3.1949e-06])\n",
            "tensor([1.7034e-06])\n",
            "tensor([-3.2072e-06])\n",
            "tensor([1.8179e-06])\n",
            "tensor([-3.0810e-06])\n",
            "tensor([1.6848e-06])\n",
            "tensor([-3.0710e-06])\n",
            "tensor([1.7881e-06])\n",
            "tensor([-2.9621e-06])\n",
            "tensor([1.5330e-06])\n",
            "tensor([-3.0368e-06])\n",
            "tensor([1.6419e-06])\n",
            "tensor([-2.9120e-06])\n",
            "tensor([1.6047e-06])\n",
            "tensor([-2.8966e-06])\n",
            "tensor([1.5721e-06])\n",
            "tensor([-2.8734e-06])\n",
            "tensor([1.6280e-06])\n",
            "tensor([-2.7746e-06])\n",
            "tensor([1.5995e-06])\n",
            "tensor([-2.7441e-06])\n",
            "tensor([1.5688e-06])\n",
            "tensor([-2.7178e-06])\n",
            "tensor([1.5292e-06])\n",
            "tensor([-2.7108e-06])\n",
            "tensor([1.5148e-06])\n",
            "tensor([-2.6741e-06])\n",
            "tensor([1.5334e-06])\n",
            "tensor([-2.6140e-06])\n",
            "tensor([1.5250e-06])\n",
            "tensor([-2.5670e-06])\n",
            "tensor([1.5134e-06])\n",
            "tensor([-2.5269e-06])\n",
            "tensor([1.4771e-06])\n",
            "tensor([-2.5083e-06])\n",
            "tensor([1.5050e-06])\n",
            "tensor([-2.4401e-06])\n",
            "tensor([1.4761e-06])\n",
            "tensor([-2.4112e-06])\n",
            "tensor([1.4724e-06])\n",
            "tensor([-2.3642e-06])\n",
            "tensor([1.4352e-06])\n",
            "tensor([-2.3390e-06])\n",
            "tensor([1.4161e-06])\n",
            "tensor([-2.3087e-06])\n",
            "tensor([1.4072e-06])\n",
            "tensor([-2.2666e-06])\n",
            "tensor([1.3839e-06])\n",
            "tensor([-2.2347e-06])\n",
            "tensor([1.3709e-06])\n",
            "tensor([-2.1968e-06])\n",
            "tensor([1.3579e-06])\n",
            "tensor([-2.1590e-06])\n",
            "tensor([1.3672e-06])\n",
            "tensor([-2.1036e-06])\n",
            "tensor([1.3448e-06])\n",
            "tensor([-2.0689e-06])\n",
            "tensor([1.3271e-06])\n",
            "tensor([-2.0352e-06])\n",
            "tensor([1.2871e-06])\n",
            "tensor([-2.0219e-06])\n",
            "tensor([1.3132e-06])\n",
            "tensor([-1.9546e-06])\n",
            "tensor([1.2787e-06])\n",
            "tensor([-1.9302e-06])\n",
            "tensor([1.2573e-06])\n",
            "tensor([-1.8957e-06])\n",
            "tensor([1.2433e-06])\n",
            "tensor([-1.8571e-06])\n",
            "tensor([1.2196e-06])\n",
            "tensor([-1.8277e-06])\n",
            "tensor([1.2149e-06])\n",
            "tensor([-1.7839e-06])\n",
            "tensor([1.1073e-06])\n",
            "tensor([-1.8110e-06])\n",
            "tensor([1.0990e-06])\n",
            "tensor([-1.7639e-06])\n",
            "tensor([9.7509e-07])\n",
            "tensor([-1.7984e-06])\n",
            "tensor([9.7742e-07])\n",
            "tensor([-1.7588e-06])\n",
            "tensor([8.0653e-07])\n",
            "tensor([-1.8226e-06])\n",
            "tensor([8.1677e-07])\n",
            "tensor([-1.7639e-06])\n",
            "tensor([6.8732e-07])\n",
            "tensor([-1.8040e-06])\n",
            "tensor([6.6869e-07])\n",
            "tensor([-1.7700e-06])\n",
            "tensor([5.7090e-07])\n",
            "tensor([-1.7958e-06])\n",
            "tensor([7.9349e-07])\n",
            "tensor([-1.6377e-06])\n",
            "tensor([6.8545e-07])\n",
            "tensor([-1.6615e-06])\n",
            "tensor([5.5367e-07])\n",
            "tensor([-1.7004e-06])\n",
            "tensor([6.2864e-07])\n",
            "tensor([-1.6503e-06])\n",
            "tensor([5.2480e-07])\n",
            "tensor([-1.6752e-06])\n",
            "tensor([6.0443e-07])\n",
            "tensor([-1.6293e-06])\n",
            "tensor([5.0245e-07])\n",
            "tensor([-1.6543e-06])\n",
            "tensor([5.9791e-07])\n",
            "tensor([-1.5893e-06])\n",
            "tensor([4.6007e-07])\n",
            "tensor([-1.6298e-06])\n",
            "tensor([6.1467e-07])\n",
            "tensor([-1.5278e-06])\n",
            "tensor([4.5588e-07])\n",
            "tensor([-1.5809e-06])\n",
            "tensor([5.9651e-07])\n",
            "tensor([-1.4883e-06])\n",
            "tensor([4.4564e-07])\n",
            "tensor([-1.5348e-06])\n",
            "tensor([5.7835e-07])\n",
            "tensor([-1.4510e-06])\n",
            "tensor([7.1572e-07])\n",
            "tensor([-1.3693e-06])\n",
            "tensor([5.7556e-07])\n",
            "tensor([-1.4133e-06])\n",
            "tensor([6.8732e-07])\n",
            "tensor([-1.3316e-06])\n",
            "tensor([5.7463e-07])\n",
            "tensor([-1.3630e-06])\n",
            "tensor([6.6590e-07])\n",
            "tensor([-1.3034e-06])\n",
            "tensor([5.4063e-07])\n",
            "tensor([-1.3341e-06])\n",
            "tensor([6.3702e-07])\n",
            "tensor([-1.2727e-06])\n",
            "tensor([5.2061e-07])\n",
            "tensor([-1.2992e-06])\n",
            "tensor([6.1840e-07])\n",
            "tensor([-1.2354e-06])\n",
            "tensor([5.0012e-07])\n",
            "tensor([-1.2638e-06])\n",
            "tensor([6.1281e-07])\n",
            "tensor([-1.1921e-06])\n",
            "tensor([4.8708e-07])\n",
            "tensor([-1.2342e-06])\n",
            "tensor([6.0024e-07])\n",
            "tensor([-1.1525e-06])\n",
            "tensor([4.8056e-07])\n",
            "tensor([-1.1898e-06])\n",
            "tensor([5.9884e-07])\n",
            "tensor([-1.1041e-06])\n",
            "tensor([4.7404e-07])\n",
            "tensor([-1.1437e-06])\n",
            "tensor([5.8813e-07])\n",
            "tensor([-1.0631e-06])\n",
            "tensor([6.9570e-07])\n",
            "tensor([-1.0040e-06])\n",
            "tensor([5.5507e-07])\n",
            "tensor([-1.0435e-06])\n",
            "tensor([6.6217e-07])\n",
            "tensor([-9.6997e-07])\n",
            "tensor([5.3365e-07])\n",
            "tensor([-1.0058e-06])\n",
            "tensor([6.4354e-07])\n",
            "tensor([-9.3086e-07])\n",
            "tensor([5.2573e-07])\n",
            "tensor([-9.6788e-07])\n",
            "tensor([6.5658e-07])\n",
            "tensor([-8.7451e-07])\n",
            "tensor([5.4901e-07])\n",
            "tensor([-9.0571e-07])\n",
            "tensor([6.3889e-07])\n",
            "tensor([-8.4029e-07])\n",
            "tensor([5.0990e-07])\n",
            "tensor([-8.8336e-07])\n",
            "tensor([6.2678e-07])\n",
            "tensor([-8.0187e-07])\n",
            "tensor([5.2666e-07])\n",
            "tensor([-8.2375e-07])\n",
            "tensor([6.2026e-07])\n",
            "tensor([-7.6601e-07])\n",
            "tensor([4.8056e-07])\n",
            "tensor([-8.0629e-07])\n",
            "tensor([5.8440e-07])\n",
            "tensor([-7.2992e-07])\n",
            "tensor([7.1572e-07])\n",
            "tensor([-6.4168e-07])\n",
            "tensor([5.9046e-07])\n",
            "tensor([-6.8313e-07])\n",
            "tensor([6.7102e-07])\n",
            "tensor([-6.2911e-07])\n",
            "tensor([5.8115e-07])\n",
            "tensor([-6.5123e-07])\n",
            "tensor([6.8545e-07])\n",
            "tensor([-5.7556e-07])\n",
            "tensor([4.5449e-07])\n",
            "tensor([-6.8825e-07])\n",
            "tensor([5.7463e-07])\n",
            "tensor([-6.0257e-07])\n",
            "tensor([6.7707e-07])\n",
            "tensor([-5.3365e-07])\n",
            "tensor([4.3865e-07])\n",
            "tensor([-6.4494e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([5.4855e-07])\n",
            "tensor([-5.7323e-07])\n",
            "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    yhat = a + b * x_train_tensor\n",
        "    error = y_train_tensor - yhat\n",
        "    loss = (error ** 2).mean()\n",
        "\n",
        "    # No more manual computation of gradients! \n",
        "    # a_grad = -2 * error.mean()\n",
        "    # b_grad = -2 * (x_tensor * error).mean()\n",
        "    \n",
        "    # We just tell PyTorch to work its way BACKWARDS from the specified loss!\n",
        "    loss.backward()\n",
        "    # Let's check the computed gradients...\n",
        "    print(a.grad)\n",
        "    print(b.grad)\n",
        "    \n",
        "    # What about UPDATING the parameters? Not so fast...\n",
        "    \n",
        "    # FIRST ATTEMPT\n",
        "    # AttributeError: 'NoneType' object has no attribute 'zero_'\n",
        "    # a = a - lr * a.grad\n",
        "    # b = b - lr * b.grad\n",
        "    # print(a)\n",
        "\n",
        "    # SECOND ATTEMPT\n",
        "    # RuntimeError: a leaf Variable that requires grad has been used in an in-place operation.\n",
        "    # a -= lr * a.grad\n",
        "    # b -= lr * b.grad        \n",
        "    \n",
        "    # THIRD ATTEMPT\n",
        "    # We need to use NO_GRAD to keep the update out of the gradient computation\n",
        "    # Why is that? It boils down to the DYNAMIC GRAPH that PyTorch uses...\n",
        "    with torch.no_grad():\n",
        "        a -= lr * a.grad\n",
        "        b -= lr * b.grad\n",
        "    \n",
        "    # PyTorch is \"clingy\" to its computed gradients, we need to tell it to let it go...\n",
        "    a.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "    \n",
        "print(a, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dc48f25",
      "metadata": {
        "id": "6dc48f25"
      },
      "source": [
        "## Dynamic Computation Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5d48c2b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "5d48c2b4",
        "outputId": "cf9300c9-4237-49d1-c8ee-3eeb2d0523b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fd2fd96bcd0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"222pt\" height=\"283pt\"\n viewBox=\"0.00 0.00 222.00 283.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 279)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-279 218,-279 218,4 -4,4\"/>\n<!-- 140541789307664 -->\n<g id=\"node1\" class=\"node\">\n<title>140541789307664</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"139,-31 74,-31 74,0 139,0 139,-31\"/>\n<text text-anchor=\"middle\" x=\"106.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (80, 1)</text>\n</g>\n<!-- 140544174373232 -->\n<g id=\"node2\" class=\"node\">\n<title>140544174373232</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-86 62,-86 62,-67 151,-67 151,-86\"/>\n<text text-anchor=\"middle\" x=\"106.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 140544174373232&#45;&gt;140541789307664 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140544174373232&#45;&gt;140541789307664</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106.5,-66.79C106.5,-60.07 106.5,-50.4 106.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"110,-41.19 106.5,-31.19 103,-41.19 110,-41.19\"/>\n</g>\n<!-- 140544174374336 -->\n<g id=\"node3\" class=\"node\">\n<title>140544174374336</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-141 0,-141 0,-122 101,-122 101,-141\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140544174374336&#45;&gt;140544174373232 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140544174374336&#45;&gt;140544174373232</title>\n<path fill=\"none\" stroke=\"black\" d=\"M59.5,-121.98C67.69,-114.23 80.01,-102.58 89.97,-93.14\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"92.48,-95.59 97.34,-86.17 87.67,-90.5 92.48,-95.59\"/>\n</g>\n<!-- 140544550773440 -->\n<g id=\"node4\" class=\"node\">\n<title>140544550773440</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-208 23.5,-208 23.5,-177 77.5,-177 77.5,-208\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n</g>\n<!-- 140544550773440&#45;&gt;140544174374336 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140544550773440&#45;&gt;140544174374336</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-176.92C50.5,-169.22 50.5,-159.69 50.5,-151.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-151.25 50.5,-141.25 47,-151.25 54,-151.25\"/>\n</g>\n<!-- 140544174373904 -->\n<g id=\"node5\" class=\"node\">\n<title>140544174373904</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-141 119,-141 119,-122 208,-122 208,-141\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 140544174373904&#45;&gt;140544174373232 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140544174373904&#45;&gt;140544174373232</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154.34,-121.98C146,-114.23 133.47,-102.58 123.32,-93.14\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125.53,-90.42 115.82,-86.17 120.76,-95.54 125.53,-90.42\"/>\n</g>\n<!-- 140544174371408 -->\n<g id=\"node6\" class=\"node\">\n<title>140544174371408</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"214,-202 113,-202 113,-183 214,-183 214,-202\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-190\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140544174371408&#45;&gt;140544174373904 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140544174371408&#45;&gt;140544174373904</title>\n<path fill=\"none\" stroke=\"black\" d=\"M163.5,-182.79C163.5,-174.6 163.5,-162.06 163.5,-151.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"167,-151.24 163.5,-141.24 160,-151.24 167,-151.24\"/>\n</g>\n<!-- 140541786062736 -->\n<g id=\"node7\" class=\"node\">\n<title>140541786062736</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"190.5,-275 136.5,-275 136.5,-244 190.5,-244 190.5,-275\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-251\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n</g>\n<!-- 140541786062736&#45;&gt;140544174371408 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140541786062736&#45;&gt;140544174371408</title>\n<path fill=\"none\" stroke=\"black\" d=\"M163.5,-243.75C163.5,-234.39 163.5,-222.19 163.5,-212.16\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"167,-212.02 163.5,-202.02 160,-212.02 167,-212.02\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "make_dot(yhat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "97e3b83b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "97e3b83b",
        "outputId": "517e8326-5109-490a-8ded-5bd1970a4ac6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fd26f3bd550>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"222pt\" height=\"338pt\"\n viewBox=\"0.00 0.00 222.00 338.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 334)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-334 218,-334 218,4 -4,4\"/>\n<!-- 140541789308144 -->\n<g id=\"node1\" class=\"node\">\n<title>140541789308144</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"139,-31 74,-31 74,0 139,0 139,-31\"/>\n<text text-anchor=\"middle\" x=\"106.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> (80, 1)</text>\n</g>\n<!-- 140541786051728 -->\n<g id=\"node2\" class=\"node\">\n<title>140541786051728</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-86 62,-86 62,-67 151,-67 151,-86\"/>\n<text text-anchor=\"middle\" x=\"106.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n</g>\n<!-- 140541786051728&#45;&gt;140541789308144 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140541786051728&#45;&gt;140541789308144</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106.5,-66.79C106.5,-60.07 106.5,-50.4 106.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"110,-41.19 106.5,-31.19 103,-41.19 110,-41.19\"/>\n</g>\n<!-- 140544174373232 -->\n<g id=\"node3\" class=\"node\">\n<title>140544174373232</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-141 62,-141 62,-122 151,-122 151,-141\"/>\n<text text-anchor=\"middle\" x=\"106.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 140544174373232&#45;&gt;140541786051728 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140544174373232&#45;&gt;140541786051728</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106.5,-121.75C106.5,-114.8 106.5,-104.85 106.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"110,-96.09 106.5,-86.09 103,-96.09 110,-96.09\"/>\n</g>\n<!-- 140544174374336 -->\n<g id=\"node4\" class=\"node\">\n<title>140544174374336</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-196 0,-196 0,-177 101,-177 101,-196\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140544174374336&#45;&gt;140544174373232 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140544174374336&#45;&gt;140544174373232</title>\n<path fill=\"none\" stroke=\"black\" d=\"M59.5,-176.98C67.69,-169.23 80.01,-157.58 89.97,-148.14\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"92.48,-150.59 97.34,-141.17 87.67,-145.5 92.48,-150.59\"/>\n</g>\n<!-- 140544550773440 -->\n<g id=\"node5\" class=\"node\">\n<title>140544550773440</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-263 23.5,-263 23.5,-232 77.5,-232 77.5,-263\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n</g>\n<!-- 140544550773440&#45;&gt;140544174374336 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140544550773440&#45;&gt;140544174374336</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-231.92C50.5,-224.22 50.5,-214.69 50.5,-206.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-206.25 50.5,-196.25 47,-206.25 54,-206.25\"/>\n</g>\n<!-- 140544174373904 -->\n<g id=\"node6\" class=\"node\">\n<title>140544174373904</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-196 119,-196 119,-177 208,-177 208,-196\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 140544174373904&#45;&gt;140544174373232 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140544174373904&#45;&gt;140544174373232</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154.34,-176.98C146,-169.23 133.47,-157.58 123.32,-148.14\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125.53,-145.42 115.82,-141.17 120.76,-150.54 125.53,-145.42\"/>\n</g>\n<!-- 140544174371408 -->\n<g id=\"node7\" class=\"node\">\n<title>140544174371408</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"214,-257 113,-257 113,-238 214,-238 214,-257\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-245\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140544174371408&#45;&gt;140544174373904 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140544174371408&#45;&gt;140544174373904</title>\n<path fill=\"none\" stroke=\"black\" d=\"M163.5,-237.79C163.5,-229.6 163.5,-217.06 163.5,-206.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"167,-206.24 163.5,-196.24 160,-206.24 167,-206.24\"/>\n</g>\n<!-- 140541786062736 -->\n<g id=\"node8\" class=\"node\">\n<title>140541786062736</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"190.5,-330 136.5,-330 136.5,-299 190.5,-299 190.5,-330\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-306\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n</g>\n<!-- 140541786062736&#45;&gt;140544174371408 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140541786062736&#45;&gt;140544174371408</title>\n<path fill=\"none\" stroke=\"black\" d=\"M163.5,-298.75C163.5,-289.39 163.5,-277.19 163.5,-267.16\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"167,-267.02 163.5,-257.02 160,-267.02 167,-267.02\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "make_dot(error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ee005882",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "ee005882",
        "outputId": "0512e137-4c27-4da8-a9c2-198a8b87f5ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fd26f3bd520>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"222pt\" height=\"448pt\"\n viewBox=\"0.00 0.00 222.00 448.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 444)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-444 218,-444 218,4 -4,4\"/>\n<!-- 140541789307264 -->\n<g id=\"node1\" class=\"node\">\n<title>140541789307264</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"133.5,-31 79.5,-31 79.5,0 133.5,0 133.5,-31\"/>\n<text text-anchor=\"middle\" x=\"106.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 140541786051680 -->\n<g id=\"node2\" class=\"node\">\n<title>140541786051680</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"154,-86 59,-86 59,-67 154,-67 154,-86\"/>\n<text text-anchor=\"middle\" x=\"106.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\n</g>\n<!-- 140541786051680&#45;&gt;140541789307264 -->\n<g id=\"edge9\" class=\"edge\">\n<title>140541786051680&#45;&gt;140541789307264</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106.5,-66.79C106.5,-60.07 106.5,-50.4 106.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"110,-41.19 106.5,-31.19 103,-41.19 110,-41.19\"/>\n</g>\n<!-- 140541786051632 -->\n<g id=\"node3\" class=\"node\">\n<title>140541786051632</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-141 62,-141 62,-122 151,-122 151,-141\"/>\n<text text-anchor=\"middle\" x=\"106.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 140541786051632&#45;&gt;140541786051680 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140541786051632&#45;&gt;140541786051680</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106.5,-121.75C106.5,-114.8 106.5,-104.85 106.5,-96.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"110,-96.09 106.5,-86.09 103,-96.09 110,-96.09\"/>\n</g>\n<!-- 140541786051728 -->\n<g id=\"node4\" class=\"node\">\n<title>140541786051728</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-196 62,-196 62,-177 151,-177 151,-196\"/>\n<text text-anchor=\"middle\" x=\"106.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n</g>\n<!-- 140541786051728&#45;&gt;140541786051632 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140541786051728&#45;&gt;140541786051632</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106.5,-176.75C106.5,-169.8 106.5,-159.85 106.5,-151.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"110,-151.09 106.5,-141.09 103,-151.09 110,-151.09\"/>\n</g>\n<!-- 140544174373232 -->\n<g id=\"node5\" class=\"node\">\n<title>140544174373232</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"151,-251 62,-251 62,-232 151,-232 151,-251\"/>\n<text text-anchor=\"middle\" x=\"106.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 140544174373232&#45;&gt;140541786051728 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140544174373232&#45;&gt;140541786051728</title>\n<path fill=\"none\" stroke=\"black\" d=\"M106.5,-231.75C106.5,-224.8 106.5,-214.85 106.5,-206.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"110,-206.09 106.5,-196.09 103,-206.09 110,-206.09\"/>\n</g>\n<!-- 140544174374336 -->\n<g id=\"node6\" class=\"node\">\n<title>140544174374336</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-306 0,-306 0,-287 101,-287 101,-306\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140544174374336&#45;&gt;140544174373232 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140544174374336&#45;&gt;140544174373232</title>\n<path fill=\"none\" stroke=\"black\" d=\"M59.5,-286.98C67.69,-279.23 80.01,-267.58 89.97,-258.14\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"92.48,-260.59 97.34,-251.17 87.67,-255.5 92.48,-260.59\"/>\n</g>\n<!-- 140544550773440 -->\n<g id=\"node7\" class=\"node\">\n<title>140544550773440</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-373 23.5,-373 23.5,-342 77.5,-342 77.5,-373\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n</g>\n<!-- 140544550773440&#45;&gt;140544174374336 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140544550773440&#45;&gt;140544174374336</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-341.92C50.5,-334.22 50.5,-324.69 50.5,-316.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-316.25 50.5,-306.25 47,-316.25 54,-316.25\"/>\n</g>\n<!-- 140544174373904 -->\n<g id=\"node8\" class=\"node\">\n<title>140544174373904</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-306 119,-306 119,-287 208,-287 208,-306\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 140544174373904&#45;&gt;140544174373232 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140544174373904&#45;&gt;140544174373232</title>\n<path fill=\"none\" stroke=\"black\" d=\"M154.34,-286.98C146,-279.23 133.47,-267.58 123.32,-258.14\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"125.53,-255.42 115.82,-251.17 120.76,-260.54 125.53,-255.42\"/>\n</g>\n<!-- 140544174371408 -->\n<g id=\"node9\" class=\"node\">\n<title>140544174371408</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"214,-367 113,-367 113,-348 214,-348 214,-367\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-355\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140544174371408&#45;&gt;140544174373904 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140544174371408&#45;&gt;140544174373904</title>\n<path fill=\"none\" stroke=\"black\" d=\"M163.5,-347.79C163.5,-339.6 163.5,-327.06 163.5,-316.55\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"167,-316.24 163.5,-306.24 160,-316.24 167,-316.24\"/>\n</g>\n<!-- 140541786062736 -->\n<g id=\"node10\" class=\"node\">\n<title>140541786062736</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"190.5,-440 136.5,-440 136.5,-409 190.5,-409 190.5,-440\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-416\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n</g>\n<!-- 140541786062736&#45;&gt;140544174371408 -->\n<g id=\"edge8\" class=\"edge\">\n<title>140541786062736&#45;&gt;140544174371408</title>\n<path fill=\"none\" stroke=\"black\" d=\"M163.5,-408.75C163.5,-399.39 163.5,-387.19 163.5,-377.16\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"167,-377.02 163.5,-367.02 160,-377.02 167,-377.02\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "make_dot(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "660e2cfd",
      "metadata": {
        "id": "660e2cfd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5cf64a4f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "id": "5cf64a4f",
        "outputId": "10b523ad-f662-40d2-9e5e-292c42b0b36e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fd26f34adc0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.43.0 (0)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"326pt\" height=\"503pt\"\n viewBox=\"0.00 0.00 326.00 503.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 499)\">\n<title>%3</title>\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-499 322,-499 322,4 -4,4\"/>\n<!-- 140544550774400 -->\n<g id=\"node1\" class=\"node\">\n<title>140544550774400</title>\n<polygon fill=\"#caff70\" stroke=\"black\" points=\"242.5,-31 188.5,-31 188.5,0 242.5,0 242.5,-31\"/>\n<text text-anchor=\"middle\" x=\"215.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\"> ()</text>\n</g>\n<!-- 140541785581312 -->\n<g id=\"node2\" class=\"node\">\n<title>140541785581312</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"260,-86 171,-86 171,-67 260,-67 260,-86\"/>\n<text text-anchor=\"middle\" x=\"215.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 140541785581312&#45;&gt;140544550774400 -->\n<g id=\"edge14\" class=\"edge\">\n<title>140541785581312&#45;&gt;140544550774400</title>\n<path fill=\"none\" stroke=\"black\" d=\"M215.5,-66.79C215.5,-60.07 215.5,-50.4 215.5,-41.34\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"219,-41.19 215.5,-31.19 212,-41.19 219,-41.19\"/>\n</g>\n<!-- 140541785579728 -->\n<g id=\"node3\" class=\"node\">\n<title>140541785579728</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"225,-141 130,-141 130,-122 225,-122 225,-141\"/>\n<text text-anchor=\"middle\" x=\"177.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\n</g>\n<!-- 140541785579728&#45;&gt;140541785581312 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140541785579728&#45;&gt;140541785581312</title>\n<path fill=\"none\" stroke=\"black\" d=\"M183.77,-121.75C189.09,-114.34 196.86,-103.5 203.38,-94.41\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"206.36,-96.26 209.34,-86.09 200.67,-92.18 206.36,-96.26\"/>\n</g>\n<!-- 140541785580592 -->\n<g id=\"node4\" class=\"node\">\n<title>140541785580592</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"205,-196 116,-196 116,-177 205,-177 205,-196\"/>\n<text text-anchor=\"middle\" x=\"160.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">PowBackward0</text>\n</g>\n<!-- 140541785580592&#45;&gt;140541785579728 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140541785580592&#45;&gt;140541785579728</title>\n<path fill=\"none\" stroke=\"black\" d=\"M163.31,-176.75C165.56,-169.72 168.8,-159.62 171.62,-150.84\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"175.02,-151.68 174.75,-141.09 168.36,-149.54 175.02,-151.68\"/>\n</g>\n<!-- 140541785583328 -->\n<g id=\"node5\" class=\"node\">\n<title>140541785583328</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"205,-251 116,-251 116,-232 205,-232 205,-251\"/>\n<text text-anchor=\"middle\" x=\"160.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n</g>\n<!-- 140541785583328&#45;&gt;140541785580592 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140541785583328&#45;&gt;140541785580592</title>\n<path fill=\"none\" stroke=\"black\" d=\"M160.5,-231.75C160.5,-224.8 160.5,-214.85 160.5,-206.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"164,-206.09 160.5,-196.09 157,-206.09 164,-206.09\"/>\n</g>\n<!-- 140541785583424 -->\n<g id=\"node6\" class=\"node\">\n<title>140541785583424</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"205,-306 116,-306 116,-287 205,-287 205,-306\"/>\n<text text-anchor=\"middle\" x=\"160.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">AddBackward0</text>\n</g>\n<!-- 140541785583424&#45;&gt;140541785583328 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140541785583424&#45;&gt;140541785583328</title>\n<path fill=\"none\" stroke=\"black\" d=\"M160.5,-286.75C160.5,-279.8 160.5,-269.85 160.5,-261.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"164,-261.09 160.5,-251.09 157,-261.09 164,-261.09\"/>\n</g>\n<!-- 140544174374336 -->\n<g id=\"node7\" class=\"node\">\n<title>140544174374336</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"101,-361 0,-361 0,-342 101,-342 101,-361\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140544174374336&#45;&gt;140541785583424 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140544174374336&#45;&gt;140541785583424</title>\n<path fill=\"none\" stroke=\"black\" d=\"M68.17,-341.98C85.79,-333.5 113.08,-320.35 133.43,-310.54\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"135.02,-313.66 142.51,-306.17 131.98,-307.36 135.02,-313.66\"/>\n</g>\n<!-- 140544550773440 -->\n<g id=\"node8\" class=\"node\">\n<title>140544550773440</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"77.5,-428 23.5,-428 23.5,-397 77.5,-397 77.5,-428\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-404\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n</g>\n<!-- 140544550773440&#45;&gt;140544174374336 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140544550773440&#45;&gt;140544174374336</title>\n<path fill=\"none\" stroke=\"black\" d=\"M50.5,-396.92C50.5,-389.22 50.5,-379.69 50.5,-371.43\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"54,-371.25 50.5,-361.25 47,-371.25 54,-371.25\"/>\n</g>\n<!-- 140541785583472 -->\n<g id=\"node9\" class=\"node\">\n<title>140541785583472</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"208,-361 119,-361 119,-342 208,-342 208,-361\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 140541785583472&#45;&gt;140541785583424 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140541785583472&#45;&gt;140541785583424</title>\n<path fill=\"none\" stroke=\"black\" d=\"M163,-341.75C162.61,-334.8 162.05,-324.85 161.55,-316.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"165.05,-315.88 160.99,-306.09 158.06,-316.27 165.05,-315.88\"/>\n</g>\n<!-- 140544174371408 -->\n<g id=\"node10\" class=\"node\">\n<title>140544174371408</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"267,-422 166,-422 166,-403 267,-403 267,-422\"/>\n<text text-anchor=\"middle\" x=\"216.5\" y=\"-410\" font-family=\"monospace\" font-size=\"10.00\">AccumulateGrad</text>\n</g>\n<!-- 140544174371408&#45;&gt;140541785583472 -->\n<g id=\"edge8\" class=\"edge\">\n<title>140544174371408&#45;&gt;140541785583472</title>\n<path fill=\"none\" stroke=\"black\" d=\"M208.68,-402.79C200.69,-393.91 188.11,-379.89 178.24,-368.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"180.64,-366.34 171.35,-361.24 175.43,-371.02 180.64,-366.34\"/>\n</g>\n<!-- 140541785580928 -->\n<g id=\"node14\" class=\"node\">\n<title>140541785580928</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"315,-361 226,-361 226,-342 315,-342 315,-361\"/>\n<text text-anchor=\"middle\" x=\"270.5\" y=\"-349\" font-family=\"monospace\" font-size=\"10.00\">MulBackward0</text>\n</g>\n<!-- 140544174371408&#45;&gt;140541785580928 -->\n<g id=\"edge13\" class=\"edge\">\n<title>140544174371408&#45;&gt;140541785580928</title>\n<path fill=\"none\" stroke=\"black\" d=\"M224.47,-402.79C232.6,-393.91 245.43,-379.89 255.48,-368.91\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"258.33,-370.98 262.5,-361.24 253.17,-366.26 258.33,-370.98\"/>\n</g>\n<!-- 140541786062736 -->\n<g id=\"node11\" class=\"node\">\n<title>140541786062736</title>\n<polygon fill=\"lightblue\" stroke=\"black\" points=\"243.5,-495 189.5,-495 189.5,-464 243.5,-464 243.5,-495\"/>\n<text text-anchor=\"middle\" x=\"216.5\" y=\"-471\" font-family=\"monospace\" font-size=\"10.00\"> (1)</text>\n</g>\n<!-- 140541786062736&#45;&gt;140544174371408 -->\n<g id=\"edge9\" class=\"edge\">\n<title>140541786062736&#45;&gt;140544174371408</title>\n<path fill=\"none\" stroke=\"black\" d=\"M216.5,-463.75C216.5,-454.39 216.5,-442.19 216.5,-432.16\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"220,-432.02 216.5,-422.02 213,-432.02 220,-432.02\"/>\n</g>\n<!-- 140541785580448 -->\n<g id=\"node12\" class=\"node\">\n<title>140541785580448</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"318,-196 223,-196 223,-177 318,-177 318,-196\"/>\n<text text-anchor=\"middle\" x=\"270.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\">MeanBackward0</text>\n</g>\n<!-- 140541785580448&#45;&gt;140541785581312 -->\n<g id=\"edge10\" class=\"edge\">\n<title>140541785580448&#45;&gt;140541785581312</title>\n<path fill=\"none\" stroke=\"black\" d=\"M266,-176.66C256.97,-158.93 236.5,-118.73 224.57,-95.32\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"227.57,-93.48 219.91,-86.16 221.33,-96.66 227.57,-93.48\"/>\n</g>\n<!-- 140541785582896 -->\n<g id=\"node13\" class=\"node\">\n<title>140541785582896</title>\n<polygon fill=\"lightgrey\" stroke=\"black\" points=\"315,-306 226,-306 226,-287 315,-287 315,-306\"/>\n<text text-anchor=\"middle\" x=\"270.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\">SubBackward0</text>\n</g>\n<!-- 140541785582896&#45;&gt;140541785580448 -->\n<g id=\"edge11\" class=\"edge\">\n<title>140541785582896&#45;&gt;140541785580448</title>\n<path fill=\"none\" stroke=\"black\" d=\"M270.5,-286.66C270.5,-269.17 270.5,-229.8 270.5,-206.27\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"274,-206.16 270.5,-196.16 267,-206.16 274,-206.16\"/>\n</g>\n<!-- 140541785580928&#45;&gt;140541785582896 -->\n<g id=\"edge12\" class=\"edge\">\n<title>140541785580928&#45;&gt;140541785582896</title>\n<path fill=\"none\" stroke=\"black\" d=\"M270.5,-341.75C270.5,-334.8 270.5,-324.85 270.5,-316.13\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"274,-316.09 270.5,-306.09 267,-316.09 274,-316.09\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Figure 5 below shows an example of this.\n",
        "# And yes, I do know that the computation itself is completely nonsense\n",
        "# It is for just understanding\n",
        "\n",
        "yhat = a + b*x_train_tensor\n",
        "error = y_train_tensor - yhat\n",
        "loss = (error**2).mean()\n",
        "\n",
        "if loss>0:\n",
        "    yhat2 = b*x_train_tensor\n",
        "    error2 = y_train_tensor - yhat2\n",
        "\n",
        "loss += error2.mean()    \n",
        "\n",
        "make_dot(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "7e6991ae",
      "metadata": {
        "id": "7e6991ae"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "053875a1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "053875a1",
        "outputId": "8a9663e8-4834-43e7-a82c-85d1fd97b25c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n",
            "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print(a, b)\n",
        "\n",
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters\n",
        "optimizer = optim.SGD([a, b], lr=lr)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    yhat = a + b * x_train_tensor\n",
        "    error = y_train_tensor - yhat\n",
        "    loss = (error ** 2).mean()\n",
        "\n",
        "    loss.backward()    \n",
        "    \n",
        "    # No more manual update!\n",
        "    # with torch.no_grad():\n",
        "    #     a -= lr * a.grad\n",
        "    #     b -= lr * b.grad\n",
        "    optimizer.step()\n",
        "    \n",
        "    # No more telling PyTorch to let gradients go!\n",
        "    # a.grad.zero_()\n",
        "    # b.grad.zero_()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "print(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "7247fead",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7247fead",
        "outputId": "7d538d5b-7741-46d5-c414-024e98d20b91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n",
            "tensor([1.0235], requires_grad=True) tensor([1.9690], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "print(a, b)\n",
        "\n",
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "# Defines a MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "\n",
        "optimizer = optim.SGD([a, b], lr=lr)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    yhat = a + b * x_train_tensor\n",
        "    \n",
        "    # No more manual loss!\n",
        "    # error = y_tensor - yhat\n",
        "    # loss = (error ** 2).mean()\n",
        "    loss = loss_fn(y_train_tensor, yhat)\n",
        "\n",
        "    loss.backward()    \n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "print(a, b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ee6bf069",
      "metadata": {
        "id": "ee6bf069"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "57d7b852",
      "metadata": {
        "id": "57d7b852"
      },
      "outputs": [],
      "source": [
        "class ManualLinearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # To make \"a\" and \"b\" real parameters of the model, we need to wrap them with nn.Parameter\n",
        "        self.a = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "        self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Computes the outputs / predictions\n",
        "        return self.a + self.b * x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3d51b739",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d51b739",
        "outputId": "74ff77c0-89fc-4600-d2b4-5a8e2f485bb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('a', tensor([0.3367])), ('b', tensor([0.1288]))])\n",
            "OrderedDict([('a', tensor([1.0235])), ('b', tensor([1.9690]))])\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "# Now we can create a model and send it at once to the device\n",
        "model = ManualLinearRegression().to(device)\n",
        "# We can also inspect its parameters using its state_dict\n",
        "print(model.state_dict())\n",
        "\n",
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # What is this?!?\n",
        "    model.train()\n",
        "\n",
        "    # No more manual prediction!\n",
        "    # yhat = a + b * x_tensor\n",
        "    yhat = model(x_train_tensor)\n",
        "    \n",
        "    loss = loss_fn(y_train_tensor, yhat)\n",
        "    loss.backward()    \n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "a990e651",
      "metadata": {
        "id": "a990e651"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "23c98f41",
      "metadata": {
        "id": "23c98f41"
      },
      "outputs": [],
      "source": [
        "class LayerLinearRegression(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Instead of our custom parameters, we use a Linear layer with single input and single output\n",
        "        self.linear = nn.Linear(1, 1)\n",
        "                \n",
        "    def forward(self, x):\n",
        "        # Now it only takes a call to the layer to make predictions\n",
        "        return self.linear(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "39433b5c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39433b5c",
        "outputId": "19904758-7cc7-4f2e-c872-3ad8d0e34c3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-0.2191]], requires_grad=True), Parameter containing:\n",
              " tensor([0.2018], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "[*LayerLinearRegression().parameters()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "6bab8435",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bab8435",
        "outputId": "4bc3a798-8c2f-4362-f731-ef08820ed093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('a', tensor([1.0235])), ('b', tensor([1.9690]))])\n"
          ]
        }
      ],
      "source": [
        "def make_train_step(model, loss_fn, optimizer):\n",
        "    # Builds function that performs a step in the train loop\n",
        "    def train_step(x, y):\n",
        "        # Sets model to TRAIN mode\n",
        "        model.train()\n",
        "        # Makes predictions\n",
        "        yhat = model(x)\n",
        "        # Computes loss\n",
        "        loss = loss_fn(y, yhat)\n",
        "        # Computes gradients\n",
        "        loss.backward()\n",
        "        # Updates parameters and zeroes gradients\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        # Returns the loss\n",
        "        return loss.item()\n",
        "    \n",
        "    # Returns the function that will be called inside the train loop\n",
        "    return train_step\n",
        "\n",
        "# Creates the train_step function for our model, loss function and optimizer\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "losses = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch in range(n_epochs):\n",
        "    # Performs one train step and returns the corresponding loss\n",
        "    loss = train_step(x_train_tensor, y_train_tensor)\n",
        "    losses.append(loss)\n",
        "    \n",
        "# Checks model's parameters\n",
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "a94957a5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a94957a5",
        "outputId": "b45e9c7f-aa9a-43bb-e66f-beb70eaf0c1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([0.7713]), tensor([2.4745]))\n",
            "(tensor([0.7713]), tensor([2.4745]))\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset, TensorDataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, x_tensor, y_tensor):\n",
        "        self.x = x_tensor\n",
        "        self.y = y_tensor\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return (self.x[index], self.y[index])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "# Wait, is this a CPU tensor now? Why? Where is .to(device)?\n",
        "x_train_tensor = torch.from_numpy(x_train).float()\n",
        "y_train_tensor = torch.from_numpy(y_train).float()\n",
        "\n",
        "train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
        "print(train_data[0])\n",
        "\n",
        "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "print(train_data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b4312116",
      "metadata": {
        "id": "b4312116"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "3165ac9f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3165ac9f",
        "outputId": "8204c359-fe11-4995-bcf6-288e380444fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[0.7852],\n",
              "         [0.8022],\n",
              "         [0.6075],\n",
              "         [0.1997],\n",
              "         [0.3309],\n",
              "         [0.6376],\n",
              "         [0.4722],\n",
              "         [0.2809],\n",
              "         [0.4938],\n",
              "         [0.5427],\n",
              "         [0.1560],\n",
              "         [0.1987],\n",
              "         [0.3745],\n",
              "         [0.0885],\n",
              "         [0.7320],\n",
              "         [0.8872]]), tensor([[2.5283],\n",
              "         [2.6229],\n",
              "         [2.4037],\n",
              "         [1.3651],\n",
              "         [1.5427],\n",
              "         [2.1930],\n",
              "         [1.9857],\n",
              "         [1.5846],\n",
              "         [1.9060],\n",
              "         [2.2161],\n",
              "         [1.2901],\n",
              "         [1.2654],\n",
              "         [1.7578],\n",
              "         [1.0708],\n",
              "         [2.4732],\n",
              "         [2.8708]])]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "5fc43db6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fc43db6",
        "outputId": "b255e02b-b56a-4085-d72c-5a26737c237c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('a', tensor([1.0202])), ('b', tensor([1.9676]))])\n"
          ]
        }
      ],
      "source": [
        "losses = []\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        # the dataset \"lives\" in the CPU, so do our mini-batches\n",
        "        # therefore, we need to send those mini-batches to the\n",
        "        # device where the model \"lives\"\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        \n",
        "        loss = train_step(x_batch, y_batch)\n",
        "        losses.append(loss)\n",
        "        \n",
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "633e7143",
      "metadata": {
        "id": "633e7143"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "75f7c370",
      "metadata": {
        "id": "75f7c370"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "\n",
        "x_tensor = torch.from_numpy(x).float()\n",
        "y_tensor = torch.from_numpy(y).float()\n",
        "\n",
        "dataset = TensorDataset(x_tensor, y_tensor)\n",
        "\n",
        "train_dataset, val_dataset = random_split(dataset, [80, 20])\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=16)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "e39b6400",
      "metadata": {
        "id": "e39b6400"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "39e96aa7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39e96aa7",
        "outputId": "0e39aaeb-b1cf-4fee-ac83-59948efb865c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('a', tensor([1.0199])), ('b', tensor([1.9728]))])\n"
          ]
        }
      ],
      "source": [
        "losses = []\n",
        "val_losses = []\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        loss = train_step(x_batch, y_batch)\n",
        "        losses.append(loss)\n",
        "        \n",
        "    with torch.no_grad():\n",
        "        for x_val, y_val in val_loader:\n",
        "            x_val = x_val.to(device)\n",
        "            y_val = y_val.to(device)\n",
        "            \n",
        "            model.eval()\n",
        "\n",
        "            yhat = model(x_val)\n",
        "            val_loss = loss_fn(y_val, yhat)\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "831fc6cd",
      "metadata": {
        "id": "831fc6cd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "51820712",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51820712",
        "outputId": "be790135-9746-482b-adf4-6a2caee55423"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('0.weight', tensor([[-0.9676]])), ('0.bias', tensor([-0.5727]))])\n",
            "OrderedDict([('0.weight', tensor([[1.9625]])), ('0.bias', tensor([1.0147]))])\n",
            "0.04879872452033063\n",
            "0.020732787506033978\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "x_tensor = torch.from_numpy(x).float()\n",
        "y_tensor = torch.from_numpy(y).float()\n",
        "\n",
        "# Builds dataset with ALL data\n",
        "dataset = TensorDataset(x_tensor, y_tensor)\n",
        "# Splits randomly into train and validation datasets\n",
        "train_dataset, val_dataset = random_split(dataset, [80, 20])\n",
        "# Builds a loader for each dataset to perform mini-batch gradient descent\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=16)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=20)\n",
        "\n",
        "# Builds a simple sequential model\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
        "print(model.state_dict())\n",
        "\n",
        "# Sets hyper-parameters\n",
        "lr = 1e-1\n",
        "n_epochs = 150\n",
        "\n",
        "# Defines loss function and optimizer\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "losses = []\n",
        "val_losses = []\n",
        "# Creates function to perform train step from model, loss and optimizer\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(n_epochs):\n",
        "    # Uses loader to fetch one mini-batch for training\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        # NOW, sends the mini-batch data to the device\n",
        "        # so it matches location of the MODEL\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        # One stpe of training\n",
        "        loss = train_step(x_batch, y_batch)\n",
        "        losses.append(loss)\n",
        "        \n",
        "    # After finishing training steps for all mini-batches,\n",
        "    # it is time for evaluation!\n",
        "        \n",
        "    # We tell PyTorch to NOT use autograd...\n",
        "    # Do you remember why?\n",
        "    with torch.no_grad():\n",
        "        # Uses loader to fetch one mini-batch for validation\n",
        "        for x_val, y_val in val_loader:\n",
        "            # Again, sends data to same device as model\n",
        "            x_val = x_val.to(device)\n",
        "            y_val = y_val.to(device)\n",
        "            \n",
        "            # What is that?!\n",
        "            model.eval()\n",
        "            # Makes predictions\n",
        "            yhat = model(x_val)\n",
        "            # Computes validation loss\n",
        "            val_loss = loss_fn(y_val, yhat)\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "print(model.state_dict())\n",
        "print(np.mean(losses))\n",
        "print(np.mean(val_losses))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "6e5ac813",
      "metadata": {
        "id": "6e5ac813"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "6ed65cad",
      "metadata": {
        "id": "6ed65cad"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a913c359",
      "metadata": {
        "id": "a913c359"
      },
      "source": [
        "### A little changes based on official pytorch for the best practise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "e2beeabe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2beeabe",
        "outputId": "18550813-367f-41ce-eab1-a745de8237c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('0.weight', tensor([[-0.9676]])), ('0.bias', tensor([-0.5727]))])\n",
            "OrderedDict([('0.weight', tensor([[-0.9676]])), ('0.bias', tensor([-0.5727]))])\n",
            "9.404897499084473\n",
            "10.201281547546387\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "\n",
        "x_tensor = torch.from_numpy(x).float()\n",
        "y_tensor = torch.from_numpy(y).float()\n",
        "\n",
        "# Builds dataset with ALL data\n",
        "dataset = TensorDataset(x_tensor, y_tensor)\n",
        "# Splits randomly into train and validation datasets\n",
        "train_dataset, val_dataset = random_split(dataset, [80, 20])\n",
        "# Builds a loader for each dataset to perform mini-batch gradient descent\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=16)\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=20)\n",
        "\n",
        "# Builds a simple sequential model\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
        "print(model.state_dict())\n",
        "\n",
        "# Sets hyper-parameters\n",
        "lr = 1e-1\n",
        "n_epochs = 150\n",
        "\n",
        "# Defines loss function and optimizer\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "losses = []\n",
        "val_losses = []\n",
        "# Creates function to perform train step from model, loss and optimizer\n",
        "train_step = make_train_step(model, loss_fn, optimizer)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(n_epochs):\n",
        "    # Uses loader to fetch one mini-batch for training\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        # NOW, sends the mini-batch data to the device\n",
        "        # so it matches location of the MODEL\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        \n",
        "        # Sets model to TRAIN mode\n",
        "        model.train()\n",
        "        # Makes predictions\n",
        "        yhat = model(x_batch)\n",
        "        # Computes loss\n",
        "        loss = loss_fn(y_batch, yhat)\n",
        "        # Computes gradients\n",
        "        loss.backward()\n",
        "        # Updates parameters and zeroes gradients\n",
        "        optimizer.zero_grad() # it is best practise to use 'zero_grad' before 'step'--> new grad values every time\n",
        "        optimizer.step()\n",
        "        # Append the loss\n",
        "        losses.append(loss.item()) \n",
        "        \n",
        "    # After finishing training steps for all mini-batches,\n",
        "    # it is time for evaluation!\n",
        "        \n",
        "    # Sets model to eval mode\n",
        "    model.eval()\n",
        "    # We tell PyTorch to NOT use autograd...\n",
        "    with torch.inference_mode(): # new version of 'torch.no_grad()' \n",
        "        \n",
        "        # Uses loader to fetch one mini-batch for validation\n",
        "        for x_val, y_val in val_loader:\n",
        "            # Again, sends data to same device as model\n",
        "            x_val = x_val.to(device)\n",
        "            y_val = y_val.to(device)\n",
        "            \n",
        "            # Makes predictions\n",
        "            yhat = model(x_val)\n",
        "            # Computes validation loss\n",
        "            val_loss = loss_fn(y_val, yhat)\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "print(model.state_dict())\n",
        "print(np.mean(losses))\n",
        "print(np.mean(val_losses))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "52c97db6",
      "metadata": {
        "id": "52c97db6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}